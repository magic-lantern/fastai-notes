{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Based on our custom MIMIC language model, train a classifier\n",
    "\n",
    "Make sure mimic_nlp_lm has been run first and sucessfully completed. That notebook builds the language model that allows classificiation to occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup filenames and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas doesn't understand ~, so provide full path\n",
    "base_path = Path.home() / 'mimic'\n",
    "\n",
    "# files used during processing - all aggregated here\n",
    "class_file = 'mimic_cl.pickle'\n",
    "\n",
    "notes_file = base_path/'noteevents.pickle'\n",
    "data_lm_file = 'mimic_lm.pickle' # actual file is at base_path/lm_file but due to fastai function, have to pass file name separately\n",
    "init_model_file = base_path/'mimic_fit_head'\n",
    "cycles_file = base_path/'cl_num_iterations.pickle'\n",
    "lm_base_file = 'mimic_lm_fine_tuned_'\n",
    "enc_file = 'mimic_fine_tuned_enc'\n",
    "class_file = 'mimic_cl.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup parameters for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data set too large to work with in reasonable time due to limted GPU resources\n",
    "pct_data_sample = 0.1\n",
    "# how much to hold out for validation\n",
    "valid_pct = 0.2\n",
    "# for repeatability - different seed than used with language model\n",
    "seed = 1776\n",
    "# for language model building - not sure how this will translate to classifier\n",
    "# batch size of 128 GPU uses 14GB RAM\n",
    "# batch size of 96 GPU uses 9GB RAM\n",
    "# batch size of 48 GPU uses 5GB RAM\n",
    "bs=96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.DataFrame()\n",
    "if os.path.isfile(notes_file):\n",
    "    print('Loading noteevent pickle file')\n",
    "    orig_df = pd.read_pickle(notes_file)\n",
    "else:\n",
    "    print('Could not find noteevent pickle file; creating it')\n",
    "    # run this the first time to covert CSV to Pickle file\n",
    "    orig_df = pd.read_csv(base_path/'NOTEEVENTS.csv', low_memory=False, memory_map=True)\n",
    "    orig_df.to_pickle(notes_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since seed is different, this should be quite different than the language model dataset.\n",
    "\n",
    "Should I show details on how many records are in language model dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orig_df.sample(frac=pct_data_sample, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Unique Categories:', len(df.CATEGORY.unique())\n",
    "print('Unique Descriptions:', len(df.DESCRIPTION.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original section from lesson3\n",
    "```python\n",
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs))\n",
    "\n",
    "data_clas.save('data_clas.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 id=\"ItemList.from_df\" class=\"doc_header\"><code>from_df</code><a href=\"https://github.com/fastai/fastai/blob/master/fastai/data_block.py#L129\" class=\"source_link\" style=\"float:right\">[source]</a><a class=\"source_link\" data-toggle=\"collapse\" data-target=\"#ItemList-from_df-pytest\" style=\"float:right; padding-right:10px\">[test]</a></h4><blockquote><p><code>from_df</code>(<strong><code>df</code></strong>:<code>DataFrame</code>, <strong><code>path</code></strong>:<code>PathOrStr</code>=<strong><em><code>'.'</code></em></strong>, <strong><code>cols</code></strong>:<code>IntsOrStrs</code>=<strong><em><code>0</code></em></strong>, <strong><code>processor</code></strong>:<code>PreProcessors</code>=<strong><em><code>None</code></em></strong>, <strong>**<code>kwargs</code></strong>) â†’ <code>ItemList</code></p>\n",
       "</blockquote>\n",
       "<div class=\"collapse\" id=\"ItemList-from_df-pytest\"><div class=\"card card-body pytest_card\"><a type=\"button\" data-toggle=\"collapse\" data-target=\"#ItemList-from_df-pytest\" class=\"close\" aria-label=\"Close\"><span aria-hidden=\"true\">&times;</span></a><p>No tests found for <code>from_df</code>. To contribute a test please refer to <a href=\"/dev/test.html\">this guide</a> and <a href=\"https://forums.fast.ai/t/improving-expanding-functional-tests/32929\">this discussion</a>.</p></div></div><p>Create an <a href=\"https://docs.fast.ai/data_block.html#ItemList\"><code>ItemList</code></a> in <code>path</code> from the inputs in the <code>cols</code> of <code>df</code>.</p>\n",
       "<p><a href=\"https://docs.fast.ai/data_block.html#ItemList.from_df\" target=\"_blank\" rel=\"noreferrer noopener\">Show in docs</a></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if os.path.isfile(base_path/data_lm_file):\n",
    "    print('loading existing language model')\n",
    "    data_lm = load_data(base_path, data_lm_file, bs=bs)\n",
    "else:\n",
    "    print('ERROR: language model file not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = base_path/class_file\n",
    "if os.path.isfile(filename):\n",
    "    data_cl = load_data(base_path, class_file, bs=bs)\n",
    "else:\n",
    "    # do I need a vocab here? test with and without...\n",
    "    data_cl = (TextList.from_df(df, 'texts.csv', cols='TEXT', vocab=data_lm.vocab)\n",
    "               #df has several columns; actual text is in column TEXT\n",
    "               .split_by_rand_pct(valid_pct=valid_pct, seed=seed)\n",
    "               #We randomly split and keep 20% for validation, set see for repeatability\n",
    "               .label_from_df(cols='DESCRIPTION')\n",
    "               #building classifier to automatically determine DESCRIPTION\n",
    "               .databunch(bs=bs))\n",
    "    data_cl.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_cl, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder(enc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change learning rate based on results from the above plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
