{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using FAST.AI for NLP\n",
    "\n",
    "Exploring the MIMIC III data set medical notes.\n",
    "\n",
    "Tried working with the full dataset, but almost every training step takes many hours (~13 for initial training), predicted 14+ per epoch for fine tuning.\n",
    "\n",
    "Instead will try to work with just 10% sample... Not sure that will work though\n",
    "\n",
    "A few notes:\n",
    "* See https://docs.fast.ai/text.transform.html#Tokenizer for details on what various artificial tokens (e.g xxup, xxmaj, etc.) mean\n",
    "* To view nicely formatted documentation on the fastai library, run commands like: ` doc(learn.lr_find)`\n",
    "\n",
    "### To Do:\n",
    "* need to evalate how changing the learning rate would alter training time\n",
    "* need to evalate how changing the learning rate would alter accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to verify that Torch can find and use your GPU, run the following code:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next cells can be used to get an idea of the speed up provided by a GPU for some operations (from https://course.fast.ai/gpu_tutorial.html)\n",
    "```python\n",
    "import torch\n",
    "t_cpu = torch.rand(500,500,500)\n",
    "%timeit t_cpu @ t_cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "t_gpu = torch.rand(500,500,500).cuda()\n",
    "%timeit t_gpu @ t_gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas doesn't understand ~, so provide full path\n",
    "base_path = Path('/home/seth/mimic')\n",
    "\n",
    "# files used during processing - all aggregated here\n",
    "notes_file = base_path/'noteevents.pickle'\n",
    "lm_file = 'mimic_lm.pickle' # actual file is at base_path/lm_file but due to fastai function, have to pass file name separately\n",
    "init_model_file = base_path/'mimic_fit_head'\n",
    "cycles_file = base_path/'num_iterations.pickle'\n",
    "lm_base_file = 'mimic_lm_fine_tuned_'\n",
    "enc_file = 'mimic_fine_tuned_enc'\n",
    "class_file = 'mimic_cl.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this doesn't free memory, can restart Python kernel.\n",
    "# if that still doesn't work, try OS items mentioned here: https://docs.fast.ai/dev/gpu.html\n",
    "def release_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see what has already been imported\n",
    "#whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Random Number seed for repeatability; set Batch Size to control GPU memory\n",
    "\n",
    "See **\"Performance notes\"** section below for how setting batch size impacts GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# previously used 48; worked fine but never seemed to use even half of GPU memory; 64 still on the small side\n",
    "bs=48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While parsing a CSV and converting to a dataframe is pretty fast, loading a pickle file is much faster.\n",
    "\n",
    "For load time and size comparison:\n",
    "* `NOTEEVENTS.csv` is ~ 3.8GB in size\n",
    "  ```\n",
    "  CPU times: user 51.2 s, sys: 17.6 s, total: 1min 8s\n",
    "  Wall time: 1min 47s\n",
    "  ```\n",
    "* `noteevents.pickle` is ~ 3.7 GB in size\n",
    "  ```\n",
    "  CPU times: user 2.28 s, sys: 3.98 s, total: 6.26 s\n",
    "  Wall time: 6.26 s\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noteevnt pickle file\n",
      "CPU times: user 1.19 s, sys: 1.27 s, total: 2.46 s\n",
      "Wall time: 2.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "orig_df = pd.DataFrame()\n",
    "if os.path.isfile(notes_file):\n",
    "    print('Loading noteevnt pickle file')\n",
    "    orig_df = pd.read_pickle(notes_file)\n",
    "else:\n",
    "    print('Could not find noteevent pickle file; creating it')\n",
    "    # run this the first time to covert CSV to Pickle file\n",
    "    orig_df = pd.read_csv(base_path/'NOTEEVENTS.csv', low_memory=False, memory_map=True)\n",
    "    orig_df.to_pickle(notes_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to data set size and performance reasons, working with a 10% sample. Use same random see to get same results from subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orig_df.sample(frac=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to free up some memory\n",
    "# orig_df = None\n",
    "# del orig_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: 982130368\n"
     ]
    }
   ],
   "source": [
    "from pympler import asizeof\n",
    "print('df:', asizeof.asizeof(df))\n",
    "#print('orig_df:', asizeof.asizeof(orig_df))\n",
    "#print('data_lm:', asizeof.asizeof(data_lm, detail=1))\n",
    "#print asizeof.asized(obj, detail=1).format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1292716</th>\n",
       "      <td>1295263</td>\n",
       "      <td>2549</td>\n",
       "      <td>159440.0</td>\n",
       "      <td>2132-04-02</td>\n",
       "      <td>2132-04-02 13:09:00</td>\n",
       "      <td>2132-04-02 13:35:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>18566.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCU NSG TRANSFER SUMMARY UPDATE: RESP FAILURE\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160271</th>\n",
       "      <td>1175599</td>\n",
       "      <td>29621</td>\n",
       "      <td>190624.0</td>\n",
       "      <td>2149-02-23</td>\n",
       "      <td>2149-02-23 03:27:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[**2149-2-23**] 3:27 AM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549380</th>\n",
       "      <td>1555118</td>\n",
       "      <td>22384</td>\n",
       "      <td>142591.0</td>\n",
       "      <td>2185-03-26</td>\n",
       "      <td>2185-03-26 17:58:00</td>\n",
       "      <td>2185-03-26 18:01:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>16985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respiratory Care\\nPt remains intubated (#7.5 E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>5743</td>\n",
       "      <td>690</td>\n",
       "      <td>152820.0</td>\n",
       "      <td>2182-09-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2182-9-12**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014768</th>\n",
       "      <td>2023163</td>\n",
       "      <td>25560</td>\n",
       "      <td>156143.0</td>\n",
       "      <td>2154-11-18</td>\n",
       "      <td>2154-11-18 10:44:00</td>\n",
       "      <td>2154-11-18 17:08:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>16888.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neonatology\\nOn exam pink active non-dysmorphi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE            CHARTTIME  \\\n",
       "1292716  1295263        2549  159440.0  2132-04-02  2132-04-02 13:09:00   \n",
       "1160271  1175599       29621  190624.0  2149-02-23  2149-02-23 03:27:00   \n",
       "1549380  1555118       22384  142591.0  2185-03-26  2185-03-26 17:58:00   \n",
       "7474        5743         690  152820.0  2182-09-14                  NaN   \n",
       "2014768  2023163       25560  156143.0  2154-11-18  2154-11-18 10:44:00   \n",
       "\n",
       "                   STORETIME           CATEGORY          DESCRIPTION     CGID  \\\n",
       "1292716  2132-04-02 13:35:00      Nursing/other               Report  18566.0   \n",
       "1160271                  NaN          Radiology  CHEST (PORTABLE AP)      NaN   \n",
       "1549380  2185-03-26 18:01:00      Nursing/other               Report  16985.0   \n",
       "7474                     NaN  Discharge summary               Report      NaN   \n",
       "2014768  2154-11-18 17:08:00      Nursing/other               Report  16888.0   \n",
       "\n",
       "         ISERROR                                               TEXT  \n",
       "1292716      NaN  CCU NSG TRANSFER SUMMARY UPDATE: RESP FAILURE\\...  \n",
       "1160271      NaN  [**2149-2-23**] 3:27 AM\\n CHEST (PORTABLE AP) ...  \n",
       "1549380      NaN  Respiratory Care\\nPt remains intubated (#7.5 E...  \n",
       "7474         NaN  Admission Date:  [**2182-9-12**]       Dischar...  \n",
       "2014768      NaN  Neonatology\\nOn exam pink active non-dysmorphi...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROW_ID           int64\n",
       "SUBJECT_ID       int64\n",
       "HADM_ID        float64\n",
       "CHARTDATE       object\n",
       "CHARTTIME       object\n",
       "STORETIME       object\n",
       "CATEGORY        object\n",
       "DESCRIPTION     object\n",
       "CGID           float64\n",
       "ISERROR        float64\n",
       "TEXT            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208318, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test sets; using same random seed so subsequent runs will generate same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1./3\n",
    "train, test = train_test_split(df, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138878, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69440, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to build initial version of language model; If running with full dataset, requires a **LOT** of RAM; using a **LOT** of CPU helps it to happen quickly as well\n",
    "\n",
    "Questions:\n",
    "\n",
    "* why does this only seem to use CPU? (applies to both both textclasdatabunch and textlist)\n",
    "* for 100% of the mimic noteevents data:\n",
    "  * run out of memory at 32 GB, error at 52 GB, trying 72GB now... got down to only 440MB free; if crash again, increase memory\n",
    "  * now at 20vCPU and 128GB RAM; ok up to 93%; got down to 22GB available\n",
    "  * succeeded with 20CPU and 128GB RAM...\n",
    "* try smaller batch size? will that reduce memory requirements?\n",
    "* with 10% dataset sample, it seems I could get by with perhaps 32GB system RAM\n",
    "\n",
    "For comparison:\n",
    "* 10% langauge model is ~ 1.2 GB in size\n",
    "  * Time to load existing language model:\n",
    "    ```\n",
    "    CPU times: user 3.29 s, sys: 844 ms, total: 4.14 s\n",
    "    Wall time: 12.6 s\n",
    "    ```\n",
    "  * Time to build language model:\n",
    "    ```\n",
    "    CPU times: user 36.9 s, sys: 8.56 s, total: 45.4 s\n",
    "    Wall time: 3min 27s\n",
    "    ```\n",
    "* 100% language model is...\n",
    "  * Time to load existing language model:\n",
    "  * Time to build language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing langauge model\n",
      "CPU times: user 1.98 s, sys: 715 ms, total: 2.69 s\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tmpfile = base_path/lm_file\n",
    "\n",
    "if os.path.isfile(tmpfile):\n",
    "    print('loading existing langauge model')\n",
    "    data_lm = load_data(base_path, lm_file, bs=bs)\n",
    "else:\n",
    "    print('creating new language model')\n",
    "    data_lm = (TextList.from_df(df, 'texts.csv', cols='TEXT')\n",
    "               #df has several columns; actual text is in column TEXT\n",
    "               .split_by_rand_pct(valid_pct=0.1, seed=seed)\n",
    "               #We randomly split and keep 10% for validation\n",
    "               .label_for_lm()\n",
    "               #We want to do a language model so we label accordingly\n",
    "               .databunch(bs=bs))\n",
    "    data_lm.save(tmpfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If need to view more data, run appropriate line to make display wider/show more columns...\n",
    "```python\n",
    "# default 20\n",
    "pd.get_option('display.max_columns')\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_columns', None) # show all\n",
    "# default 50\n",
    "pd.get_option('display.max_colwidth')\n",
    "pd.set_option('display.max_colwidth', -1) # show all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pacs . xxmaj bp went back to 150 / 80 . xxup hr varies between 80s to low 90s at rest up to 1-teens with activity . xxup bp varies more widely between 1-teens / 70s at rest up to 170 / 90s with activity . xxmaj she continues on dilt 90 mg po qid . xxmaj she was xxup k+ replaced today . \\n  xxup resp : xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>spine , xxup trauma ( xxup with xxup flex &amp; xxup ext ) ; t - l xxup spine 3 ' xxup film xxup ap &amp; xxup lat xxmaj clip # [ * * xxmaj clip xxmaj number ( xxmaj radiology ) xxunk * * ] \\n  xxmaj reason : s / p xxup mvc , s / p xxup mvc \\n  xxrep 78 _ \\n  [</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>views , xxup pa xxup and xxup lateral \\n \\n  xxmaj history of xxup cabg . \\n \\n  xxmaj status post xxup cabg . xxup picc line is in mid xxup svc . xxmaj the lungs are clear . xxmaj no \\n  pneumothorax or pleural effusion . xxmaj there is cardiomegaly but no evidence for \\n  xxup chf . \\n \\n \\n  xxbos [ *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>) xxmaj tablet , xxmaj delayed xxmaj release ( xxup e.c. ) xxup po xxup tid ( 3 times a day ) . \\n  4 . xxmaj calcium xxmaj acetate 667 mg xxmaj capsule xxmaj sig : xxmaj three ( 3 ) xxmaj capsule xxup po xxup tid \\n  w / xxup meals ( 3 xxup times a xxup day xxup with xxup meals ) . \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>has been \\n  pumping while in [ * * xxmaj hospital1 468 * * ] , and in touch with lactation \\n  consultant about low production of milk . xxmaj abdomen is soft , \\n  pink , active bowel sounds , no loops , xxup ag stable . xxmaj voiding , no \\n  stool this shift . xxmaj no spits , min residuals . tolerating \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()\n",
    "# how to look at original version of text\n",
    "#df[df['TEXT'].str.contains('being paralyzed were discussed', case=False)].TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as of June 2019, this automatically loads and initializes the model based on WT103 from\n",
    "# https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz; will auto download if not already on disk\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxV5bn3/8+VeSADQ5jnQVQoYwSRiqIehdpqbetYtU6ltE49PR2fPrY+7emptrWng7+qaGtbx1qtU7WIrXVGISDIPEcIQwhzAiQhyfX7Y280hoQEkrVX9s73/XrtV/Ze695rXzc78GWte617mbsjIiJyvJLCLkBEROKbgkRERFpFQSIiIq2iIBERkVZRkIiISKukhF3AserWrZsPHDgw7DJEROLKggULdrh7QRDbDjRIzCwfeAAYCThwnbvPrbf+ROBBYBzwfXf/RXPbHDhwIEVFRQFVLCKSmMzsg6C2HfQeya+B2e7+BTNLA7IarN8F3AJ8NuA6REQkIIGNkZhZLjAF+D2Au1e7+576bdx9u7vPBw4FVYeIiAQryMH2wUAZ8KCZvWdmD5hZ9vFsyMxmmFmRmRWVlZW1bZUiItIqQQZJCpGxj3vcfSywH/ju8WzI3We5e6G7FxYUBDJWJCIixynIICkBStz93ejrJ4kEi4iIJJDAgsTdtwGbzGx4dNHZwPKgPk9ERMIR9FlbNwOPRM/YWg9ca2YzAdz9XjPrCRQBuUCdmX0dONnd9wVcl4iItJFAg8TdFwGFDRbfW2/9NqBvkDUctn1fJQ+8uYHrJg+iZ15GLD5SRKRD6DBTpLyzYRe/f3MDp//sFb7z5PusL6sIuyQRkYQQd1OkHK8LRvdmbL987n9jPX+Zv4knFmxi2oiefGZ0byYP7UZeZmrYJYqIxCWLtzskFhYWemunSCkrr+KPb2/g4Xc2svfgIZKTjPH9O3PG8AK+ML4vPXJ16EtEEouZLXD3hkMNbbPtjhgkh9XU1vHepj28tqqMV1dvZ+nmfaSlJHHZKf2YecYQeudntsnniIiETUFST1sGSUMbdx7gntfW8uSCEgC+ML4fXztzCP26NJwiTEQkvihI6gkySA7bvOcg9766jr/M30SdO58f15cbpw6lf1cFiojEJwVJPbEIksO27o0EymPzN1Fb53xubB+umjSAkb3zSEqymNQgItIWFCT1xDJIDtu2t5J7X1vHo/M2Ul1TR5fsNCYP7cbpw7rRIzeD0n2VlO6tpLS8kgPVtWSnpZCVlkxmWjJ5man0ysugV14mvfIz6JadrhASkZhTkNQTRpActrOiitfXlPHG6h28vmYHOyqqPra+c1YqWWkpHKiu4UB1LVU1dUdso0t2Gj/93Cc4b0TPWJUtIqIgqS/MIKnP3VlVWk55ZQ09czMoyEknIzX5Y21q65w9B6rZurcy+jjIE0WbWLp5H9dOHsh3p59IekpyE58gItJ2ggySDnNBYlszM07smXvUNslJRtdO6XTtlM7IPnkAXHpKP+74x0oefKuYouLd3H3FWAZ0Pa7btIiItAvaIwnJS8u28a2/LqbO4dazh3H1aQPa5d7J6tJy/r1yO1v2HKR0XxXbyyvZtb+afl2yGNu/M+P65zO2X2fysj4+M0BNbR37q2s5UF3D/qoaCnIyNHuASIh0aKueRAkSgJLdB7jtmaX8e1UZA7pm8b3pJ3LeiJ6YhTsYv6a0nL+/v5UXl2xlzfbInGS5GSl0z82ge046nbPTWLe9gtWl5dRFf31S6p1A4EQO69WXmZrMpaf048tTBtNHF3qKxJyCpJ5ECpLDXl9dxn+/sJzVpRVMGNSF//qPE5g4uGtMa9hfVcPzi7fw2LyNLC7ZixlMGNiF80f1YtqInnRvZNqYiqoa3t+0h0Ule9hfVfOxdWnJyWSnJ9MpPYXMtGTeWLODZ97bDMAFY3pz3oie7D14iB0VVeysqGbX/mr2HTzEvspD7DtYQ507pw7uypnDC5g0pCtZaToKK9IaCpJ6EjFIIHIo6PH5m/jVP1ezo6KawgGduXHqUM4cXnDUPZTlW/axYus+tu49yOY9kQH91OQkhnXvxPCeOQzrnkO3TmmUV9VQXllDeeUhKiprqKyp5WB1HQcP1bJ2ewXPL95CRVUNJ/ToxOUT+nP+qF50z2nbOce27DnIA29s4LF5Gzl4qPbD5VlpyXTJTiMvM5XcjFRyM1Ooqqnj3fW7OHiolrSUJMb0y8eAg4dq2V9VQ1VNHX3yMxnWoxPDuucwrEcnTuyZS5fstDatWSRRKEjqSdQgOexgdS1PFG3ivtfWsWVvJSf1yuXTo3oxcVAXRvXNJy0liYqqGp5bFNl7WLJ574fv7ZqdRq/8DKoO1bFhx35q6lr23aanJPHpUb25YmI/xvXvHPihtT0HqineeYCu2Wl07ZTW5N5G5aFa5hfv4tVVZSzcuJvU5CSy05LJSkshNdnYuOsAa7ZXUF750d5Qj9x0TuqVy0m9cumTn0nX7DS6RB/9u2a1y3EokVhQkNST6EFyWHVNHc8u2swf3ipmxdbIDSMzUpMY2TuPFVv3sb+6lhN75nD5hP6cPqwbvfMzP3b6cXVNJExWl5az5+AhcjNSyMlIIScj9WMXTGakJpOVlkxqcnzemsbd2V5exerSclZuLWfF1n0s37qPtdsrjgjS3IwUzh/Vi4vG9uWUgcEHpkh7oiCpp6MESX07K6qYX7ybeRt2sXDjboZ178QVE/tHDvfoH8NGVdfUsftA9YfjLzsqqnhtdRmzl27j4KFa+nbO5LQhXcnNSCUnI5WcjBT6d8ni9BO6aa9FElLcBomZ5QMPACOJnMxznbvPrbfegF8DnwIOANe4+8KjbbMjBom0nf1VNcxZvo2/LdzMqm2RC0rrj9cc3mu5cEwfJgzsoulsJGHE8wWJvwZmu/sXzCwNaDh97nRgWPQxEbgn+lMkENnpKVw0ti8Xje374bJDtXVUVNawuGQPzy7awjPvbeGxeZvolZfBtJE9+dQnejG+f2eFikgTAtsjMbNcYDEw2Jv4EDO7D3jV3R+Lvl4FnOnuW5varvZIJGgHqmt4eXkpzy/ewutrdlBdU0dBTjrnnNSD0X3zOLl3Lif0yDliShyR9ixe90gGA2XAg2Y2GlgA3Oru++u16QNsqve6JLrsY0FiZjOAGQD9+/cPsGQRyEpL4cIxfbhwTB/KKw/xysrtzF667cPrbCAy/c2gbtkM7pbNoG7ZDOiazcCuWeRlpZKTnhq5hiYjReMt0iEEGSQpwDjgZnd/18x+DXwXuK1em8aOFRyx9+Lus4BZENkjCaBWkUblZKR+GCp1dc6m3Qc+vHZn+dZy1u/Yz6uryqiuPXKmZ4BB3bIZP6AzhQM6UziwC0MKsnWChCScIIOkBChx93ejr58kEiQN2/Sr97ovsCXAmkSOW1KSMaBrZO9j+id6fbi8ts7ZuvcgG3cdYN/BGiqqaqioPMTegzUs2byXf60o/fD2zV2y0zhlYGcmDOrKxEFdOKlXLskae5E4F1iQuPs2M9tkZsPdfRVwNrC8QbPngJvM7HEig+x7jzY+ItIeJScZfTtn0bdz47didnfW79jPguLdzCvexbwNu3hpWSkAA7pmcfNZw/jsmN6kxOm1PCJBn/47hsjpv2nAeuBa4FIAd783evrv3cA0Iqf/XuvuRx1J12C7JIKtew8yd91Ofv/mBpZt2cegbtncfNZQLhitQJFgxO11JEFQkEgicXfmLC/lV/9cw4qt++iTn8lnx/bmorF9Gdq9U9jlSQJRkNSjIJFEVFcXCZTH5m3kjTVl1DmM6pvHlacO4OLxfTVAL62mIKlHQSKJbvu+Sp5bvIUnF5Swcls5nx7Vizs/P4rsdE2lL8cvyCDRwViRdqZ7bgY3nD6YF285nW9PG86LS7Zy4f/3FmujNxkTaW8UJCLtVFKS8bUzh/LQ9RPZvb+aC+9+k7+/r7Pjpf1RkIi0c5OHduPvt3ySYT1yuOnR9/jKQ0Vs2XMw7LJEPqQgEYkDvfIyeeIrk/j2tOG8trqMc375Gve/vp5DTVxRLxJLChKROJGWksTXzhzKy/95BqcO7spPXlzBBXe/pb0TCZ2CRCTO9OuSxe+/VMi9V46jZNcBLp01l5LdB8IuSzowBYlIHDIzpo3sxcM3TGTvgUNcet87bNypMJFwKEhE4tjofvk8+uVTqaiq4bJZcynesb/5N4m0MQWJSJwb2SePx758KgcP1XLprLlsUJhIjClIRBLAyb1zeWzGqRyqdS6f9Q4f7FSYSOwoSEQSxIk9c3nkholU1tRyxf3vsmmXxkwkNhQkIgnkpF65PHz9RMorD3H5/e+wWacGSwwoSEQSzMg+eZGzuQ4e4vJZ7+g6EwmcgkQkAY3qm8+fr5vA7v3VXHLfXI2ZSKAUJCIJamz/zjzy5YlUVNVwyX1zWbu9POySJEEpSEQS2Ki++fxlxiRq6+DS+95h2Za9YZckCSjQIDGzYjNbYmaLzOyIu1GZWWcze9rM3jezeWY2Msh6RDqi4T1z+OvMSaSnJHH5rHdYUqIwkbYViz2Sqe4+pok7c/0fYJG7jwKuBn4dg3pEOpxB3bJ5YuYkcjJSmfFQETsrqsIuSRJI2Ie2Tgb+BeDuK4GBZtYj3JJEElPfzlncd9V4du6v5ubH3qNGU9BLGwk6SByYY2YLzGxGI+sXA58DMLMJwACgb8NGZjbDzIrMrKisrCzQgkUS2cg+efz3Z0fy9rqd3PXy6rDLkQQRdJBMdvdxwHTgRjOb0mD9HUBnM1sE3Ay8B9Q03Ii7z3L3QncvLCgoCLhkkcR2SWE/Lp/Qn3teXcdLy7aFXY4kgECDxN23RH9uB54GJjRYv8/dr3X3MUTGSAqADUHWJCJw+wUnM7pvHt98YjHryyrCLkfiXGBBYmbZZpZz+DlwLrC0QZt8M0uLvrwBeN3d9wVVk4hEpKck87srx5OaksQV97/LmlJdYyLHL8g9kh7Am2a2GJgHvODus81sppnNjLY5CVhmZiuJHP66NcB6RKSePvmZPHLDRGrqnEvum8viTXvCLknilLl72DUck8LCQi8qOuKSFBE5Th/s3M+Vv3+XXRXV3H91IacN7RZ2SRIAM1vQxGUYrRb26b8iErIBXbN5cuZp9OmcyTUPzmeOBuDlGClIRIQeuRk88ZVJnNw7lxsfXci/VpSGXZLEEQWJiACQn5XGn6+fwEm9cvnqwwt5bbWu2ZKWUZCIyIdyM1L583UTGNq9EzP+XMTb63aEXZLEAQWJiHxMflYaD98wkQFds7j+j0XML94VdknSzilIROQIXbLTeOSGU+mVn8F1D85n6WbNGCxNU5CISKMKctJ55IaJ5GamcvUf5rF2u66Al8YpSESkSb3yMnno+gkkGVz9+3fZrPu/SyMUJCJyVIMLOvGn6yZQXlnDVQ+8yw7dy0QaUJCISLNG9M7jD9eewpa9B7nmwXlUVB0xSbd0YAoSEWmRUwZ24Z4vjmfF1nK++vACqmt0YyyJUJCISItNPbE7P/3cJ3hjzQ6++9T7xNtcfRKMlLALEJH4cklhP0r3VnLXy6vpkZfBd6adGHZJEjIFiYgcs5vOGsrWfZXc8+o6euZm8KXTBoZdkoRIQSIix8zM+NEFI9i+r4rbn19G386ZnH1Sj7DLkpBojEREjktKchK/vXwsI3rncstj77Fqm+6y2FEpSETkuGWmJXP/1YVkp6dw/Z/ms1PXmHRIgQaJmRWb2RIzW2RmR9zW0MzyzOx5M1tsZsvM7Nog6xGRttcrL5NZVxdSVl7FzIcXUFVTG3ZJEmOx2COZ6u5jmrjF443AcncfDZwJ3GVmaTGoSUTa0Jh++fz84tHML97N/316qU4L7mDCHmx3IMfMDOgE7AJ0yaxIHLpgdG/Wlpbzm1fWMrxnDjecPjjskiRGgt4jcWCOmS0wsxmNrL8bOAnYAiwBbnX3Iy6XNbMZZlZkZkVlZbprm0h79fVzTuC8ET34nxdX8LrusNhhBB0kk919HDAduNHMpjRYfx6wCOgNjAHuNrPchhtx91nuXujuhQUFBQGXLCLHKynJ+OUlYzihRw43PbqQDTv2h12SxECgQeLuW6I/twNPAxMaNLkW+JtHrAU2ALpMViSOZaencP/VhSQnGV/+cxHllYfCLkkCFliQmFm2meUcfg6cCyxt0GwjcHa0TQ9gOLA+qJpEJDb6dcnid18cT/GO/dz6+CJq6zT4nsiC3CPpAbxpZouBecAL7j7bzGaa2cxomx8Dp5nZEuBfwHfcfUeANYlIjEwa0pUffuZkXlm5nYfmFoddjgQosLO23H09MLqR5ffWe76FyJ6KiCSgK08dwJzlpdw1ZzXnj+pNQU562CVJAHRlu4gExsz4fxeMoLKmlp/+Y0XY5UhAFCQiEqjBBZ2YMWUwf1u4mXkbdoVdjgRAQSIigbtp6jD65Gdy2zNLOVSrOysmGgWJiAQuMy2ZH3zmZFaVlvOnt4vDLkfamIJERGLi3JN7MHV4Ab/65xpK91WGXY60IQWJiMSEmXH7BSOorq3jpy9q4D2RKEhEJGYGdM3mK1MG88yiLRp4TyAKEhGJqa+dOZQ++Zn88LlluuI9QShIRCSmMtOS+f75J7Fi6z4effeDsMuRNqAgEZGYmz6yJ6cN6cov5qxm1/7qsMuRVlKQiEjMHb7ifX9VDT9/aVXY5UgrtShIzGyImaVHn59pZreYWX6wpYlIIhvWI4cvnTaQx+dv5P2SPWGXI63Q0j2Sp4BaMxsK/B4YBDwaWFUi0iHces4wuman84Nnl1Gngfe41dIgqXP3GuAi4Ffu/p9Ar+DKEpGOIDcjle9NP5FFm/bw5IKSsMuR49TSIDlkZpcDXwL+Hl2WGkxJItKRfG5cHwoHdOaO2SvZe0B3U4xHLQ2Sa4FJwE/cfYOZDQIeDq4sEekozIwfXTiSPQequetlDbzHoxYFibsvd/db3P0xM+sM5Lj7HQHXJiIdxMm9c7nq1AE8/M4HLNuyN+xy5Bi19KytV80s18y6AIuBB83sl8GWJiIdyTfOHU7nrDR+8Owy3DXwHk9aemgrz933AZ8DHnT38cA5zb3JzIrNbImZLTKzokbWfyu6bpGZLTWz2mhYiUgHk5eZynemnciCD3bz1MLNYZcjx6ClQZJiZr2AS/hosL2lprr7GHcvbLjC3X8eXTcG+B7wmrtrJjeRDuoL4/sytn8+d/xjBXsPauA9XrQ0SH4EvASsc/f5ZjYYWNPGtVwOPNbG2xSROJKUZPz4wpHs2l/NXXM08B4vWjrY/ld3H+XuX42+Xu/un2/JW4E5ZrbAzGY01cjMsoBpRC58bGz9DDMrMrOisrKylpQsInFqZJ+8Dwfel27WwHs8aOlge18ze9rMtptZqZk9ZWZ9W/DWye4+DpgO3GhmU5po9xngraYOa7n7LHcvdPfCgoKClpQsInHsG+cOp0t2Ov/3maW64j0OtPTQ1oPAc0BvoA/wfHTZUbn7lujP7cDTwIQmml6GDmuJSFReZir/51ORK97/UrQp7HKkGS0NkgJ3f9Dda6KPPwJH3TUws2wzyzn8HDgXWNpIuzzgDODZY6pcRBLaRWP7MGFQF+6cvVJTzbdzLQ2SHWZ2pZklRx9XAjubeU8P4E0zWwzMA15w99lmNtPMZtZrdxEwx933H3v5IpKozCID7+WVmmq+vUtpYbvrgLuB/yUygP42kWlTmuTu64HRjSy/t8HrPwJ/bGEdItKBDO+Zw1WnDuChdz7gy6cPYnBBp7BLkka09Kytje5+gbsXuHt3d/8skYsTRUQCddNZQ0lPSeKXL68OuxRpQmvukPiNNqtCRKQJ3Tqlc/0nB/H397fqdOB2qjVBYm1WhYjIUdxw+mDyMlN1kWI71Zog0cndIhITeZmpfPXMIfx7VRnzizWLUntz1CAxs3Iz29fIo5zINSUiIjHxpUkD6Z6Tzs9mr9TswO3MUYPE3XPcPbeRR467t/SMLxGRVstMS+bms4cxv3g3r67WVEntSWsObYmIxNSlhf3o3yWLX85Zrb2SdkRBIiJxIy0liZlnDGHJ5r3ML94ddjkSpSARkbhy0dg+5Gel8uBbG8IuRaIUJCISVzLTkrnslP68tGwbJbsPhF2OoCARkTh09aQBmBkPzf0g7FIEBYmIxKHe+ZlMG9GTx+Zt5EB1TdjldHgKEhGJS9d9ciD7Kmt4auHmsEvp8BQkIhKXxvXvzKi+efzxrQ26i2LIFCQiEpfMjGsnD2Rd2X7eWLsj7HI6NAWJiMSt8z/Rm4KcdP7wpk4FDpOCRETiVlpKEtecNpDXVpfx9jrtlYQl0CAxs2IzW2Jmi8ysqIk2Z0bXLzOz14KsR0QSz/WfHES/Lpn88NllHKqtC7ucDikWeyRT3X2Muxc2XGFm+cDvgAvcfQRwcQzqEZEEkpGazA8+PYI12yv409vFYZfTIYV9aOsK4G/uvhHA3beHXI+IxKFzTurO1OEF/Oqfa9i+rzLscjqcoIPEgTlmtsDMZjSy/gSgs5m9Gm1zdcD1iEgCMjN++JkRVNfU8T8vrgi7nA4n6CCZ7O7jgOnAjWY2pcH6FGA8cD5wHnCbmZ3QcCNmNsPMisysqKxM9yEQkSMN7JbNjCmDeWbRFt5dvzPscjqUQIPE3bdEf24HngYmNGhSAsx29/3uvgN4HRjdyHZmuXuhuxcWFBQEWbKIxLEbpw6lT34mP3xuGTUaeI+ZwILEzLLNLOfwc+BcYGmDZs8Cp5tZipllARMB7ZeKyHHJTEvm++efxMpt5Ty5oCTscjqMIPdIegBvmtliYB7wgrvPNrOZZjYTwN1XALOB96NtHnD3hmEjItJi00f2ZFz/fH758mpN6BgjFm+3qywsLPSiokYvSRERAWDBB7v4/D1z+cZ/nMAtZw8Lu5x2wcwWNHYZRlsI+/RfEZE2N35AF6aN6Ml9r62jrLwq7HISnoJERBLSt6cNp6qmjl//a3XYpSQ8BYmIJKTBBZ24YmJ/Hpu3ibXbK8IuJ6EpSEQkYd1y9jAyU5P52eyVYZeS0BQkIpKwunVKZ+YZg5mzvJSFG3eHXU7CUpCISEK7dvIgOmel8tt/rQm7lISlIBGRhJadnsINpw/m36vKWFKyN+xyEpKCREQS3tWTBpCbkcJvXtFeSRAUJCKS8HIyUrnuk4N4eXkpK7buC7uchKMgEZEO4drTBtEpPYW7X1kbdikJR0EiIh1CXlYq15w2kBeXbmVNaXnY5SQUBYmIdBjXfXIQmanJ3P1v7ZW0JQWJiHQYXbLTuOrUATy/eIuudm9DChIR6VC+PGUw2Wkp/OSF5WGXkjAUJCLSoXTrlM6t5wzj36vKeGVladjlJAQFiYh0OFdPGsiQgmx+9Pxyqmpqwy4n7ilIRKTDSUtJ4oefGUHxzgP84c3isMuJewoSEemQppxQwH+c3IPfvrKG0n2VYZcT1wINEjMrNrMlZrbIzI64P66ZnWlme6PrF5nZD4KsR0SkvtvOP5maOueOf2ia+dZIicFnTHX3HUdZ/4a7fzoGdYiIfEz/rlnMOH0wd/97LVee2p/xA7qEXVJc0qEtEenQvjZ1CAU56fziJd2S93gFHSQOzDGzBWY2o4k2k8xssZn9w8xGNNbAzGaYWZGZFZWVlQVXrYh0OFlpKXz1jCHMXb+Tt9cd7eCJNCXoIJns7uOA6cCNZjalwfqFwAB3Hw38FnimsY24+yx3L3T3woKCgmArFpEO54qJ/emRm86vXl6Du4ddTtwJNEjcfUv053bgaWBCg/X73L0i+vxFINXMugVZk4hIQxmpydw4dSjzinfx1tqdYZcTdwILEjPLNrOcw8+Bc4GlDdr0NDOLPp8QrUffoojE3KWn9KNXXga/fHmV9kqOUZB7JD2AN81sMTAPeMHdZ5vZTDObGW3zBWBptM1vgMtc36CIhCA9JZmbzhrKwo17eG21xmKPhcXbv9uFhYVeVHTEJSkiIq1WXVPHWXe9StfsNJ65cTLRAyYJwcwWuHthENvW6b8iIlFpKUncctYwFpfs5eXlmtCxpRQkIiL1XDSuD8O6d+K2Z5eya3912OXEBQWJiEg9qclJ/OqyMezef4jvPPW+Bt5bQEEiItLAiN55fHvacF5eXsoj724Mu5x2T0EiItKI6yYPYsoJBfz478tZU1oedjntmoJERKQRSUnGLy4eRaf0FG55fBGVh3QDrKYoSEREmtA9J4NfXDyaFVv3aar5o1CQiIgcxdQTu3Pd5EH88e1iZi/dFnY57ZKCRESkGd+dfiKj++bxrScXs2nXgbDLaXcUJCIizUhLSeLuK8ZhwE2PLqS6pi7sktoVBYmISAv065LFzy8ezeKSvfz0HyvCLqddUZCIiLTQeSN6cu3kgTz4VjGzl24Nu5x2Q0EiInIMvjf9JEb3zeObf32fdWUVYZfTLihIRESOQVpKEr+7cjxpKUnMfGgBFVU1YZcUOgWJiMgx6pOfyW8vH8u6sgq+/eTiDj8fl4JEROQ4TB7ajW9PO5EXl2zj/jfWh11OqBQkIiLH6StTBjN9ZE/u+MdK3l67I+xyQqMgERE5TmbGzy8ezeCCTtz82HtsL68Mu6RQBBokZlZsZkvMbJGZNXl/XDM7xcxqzewLQdYjItLWOqWncM8Xx1FRVcN/PbGYurqON14Siz2Sqe4+pql7BZtZMnAn8FIMahERaXPDeuRw26dP5o01O/j9mxvCLifm2sOhrZuBp4DtYRciInK8vjixP+ee3IOfvbSSJSV7wy4npoIOEgfmmNkCM5vRcKWZ9QEuAu492kbMbIaZFZlZUVlZWUCliogcPzPjzs+Pomt2Orc8/h77O9D1JUEHyWR3HwdMB240sykN1v8K+I67H/WOMe4+y90L3b2woKAgqFpFRFqlc3Ya/3vpGIp37uf255aFXU7MBBok7r4l+nM78DQwoUGTQuBxMysGvgD8zsw+G2RNIiJBmjSkKzdNHcpfF5Twl/kd437vgQWJmWWbWc7h58C5wNL6bdx9kLsPdPeBwJPA19z9maBqEhGJha+fcwKfHNqN255dxvsle8IuJ3BB7pH0AN40s8XAPOAFd59tZjPNbGaAnysiEqrkJOM3l4+loLrfrAgAAAscSURBVFM6Mx9awM6KqrBLCpTF2xwxhYWFXlTU5CUpIiLtxpKSvXz+3rc5ZWBn/nTtBFKSwztR1swWNHUZRmu1h9N/RUQS0if65vHfnx3JW2t38os5q8MuJzApYRcgIpLILinsx+JNe7j3tXX0yc/gqkkDwy6pzSlIREQCdvsFI9heXsVtzy4jPTWZSwr7hV1Sm9KhLRGRgKUmJ3H3FWM5fVg3vvvU+zy3eEvYJbUpBYmISAykpyQz66pCCgd24T//soiXlm0Lu6Q2oyAREYmRzLRk/nDNKXyiTx43P/oezy7aHHZJbUJBIiISQ53SU/jTtRMY2z+fWx9fxC/nrIr7qecVJCIiMZaXlcpD10/kksK+/OaVtdz8+HtUHjrqlIPtms7aEhEJQVpKEnd+fhRDCjpxx+yVlOw6wO0XjGBMv3zMLOzyjomCREQkJGbGV84YwqBu2fzXE4u56HdvM7JPLlefOpDPjO5NarJRvPMAq0vLWV1aztj+nTnjhPY3A7qmSBERaQcqqmp4+r3NPDS3mNWlFWSnJXOo1qmurQPADG48cyjfPG/4cW0/yClStEciItIOdEpP4apTB3DlxP7M27CLZxZtITczhRO653BCjxyGdu9EZlpy2GU2SkEiItKOmBkTB3dl4uCuYZfSYjprS0REWkVBIiIiraIgERGRVlGQiIhIqwQaJGZWbGZLzGyRmR1xzq6ZXWhm7x9eb2afDLIeERFpe7E4a2uqu+9oYt2/gOfc3c1sFPAEcGIMahIRkTYS6um/7l5R72U2EF9XR4qISOBjJA7MMbMFZjajsQZmdpGZrQReAK5ros2M6KGvorKysgDLFRGRYxXoFClm1tvdt5hZd+Bl4GZ3f72JtlOAH7j7Oc1sswz4oMHiPGBvM8uO9vrw8/rLugFNHZJrTmP1HEubY+1Pc89b05fmam2uTSJ9Ny3pS8NlQX43+j07+vJ4/T1ral1rv5tsdw9moi53j8kDuB34ZjNtNgDdjmPbs5pbdrTXh583WFbUir4eUc+xtDnW/jT3vDV9aW1/Eum7aUlfYvnd6PcsMX/P2uN309wjsENbZpZtZjmHnwPnAksbtBlq0fmSzWwckAbsPI6Pe74Fy472+vkm2hyvlmznaG2OtT8ted4arelPIn03LelLw2VBfjf6PTv68nj9PWtqXZjfzVEFdmjLzAYDT0dfpgCPuvtPzGwmgLvfa2bfAa4GDgEHgW+5+5uBFHSMzKzIA5opM9YSqS+QWP1RX9qvROpP0H0J7Kwtd18PjG5k+b31nt8J3BlUDa00K+wC2lAi9QUSqz/qS/uVSP0JtC9xdz8SERFpXzRFioiItIqCREREWiXhg8TM/mBm281safOtj3jv+OhcYWvN7DeHzzCLrrvZzFaZ2TIz+1nbVn3Umtq8P2Z2u5ltjs55tsjMPtX2lTdaTyDfTXT9N83Mzaxb21XcbE1BfDc/rjcf3Rwz6932lTdaTxB9+bmZrYz252kzy2/7ypusKYj+XBz9+19nZoEPyremD01s70tmtib6+FK95Uf9u9WoIM8tbg8PYAowDlh6HO+dB0wCDPgHMD26fCrwTyA9+rp7nPfndpq5xide+hJd1w94iciFq8d8XVJ76g+QW6/NLcC9cdyXc4GU6PM7gTvj/Ls5CRgOvAoUttc+ROsb2GBZF2B99Gfn6PPOR+vv0R4Jv0fikSvpd9VfZmZDzGx2dOqWN8zsiIkizawXkb/Ecz3yp/tn4LPR1V8F7nD3quhnbA+2Fx8JqD+hCLAv/wt8mxjP3RZEf9x9X72mMZuPLqC+zHH3mmjTd4C+wfbiIwH1Z4W7r4pF/dHPO64+NOE84GV33+Xuu4nMPDLteP+dSPggacIsItO1jAe+CfyukTZ9gJJ6r0uiywBOAE43s3fN7DUzOyXQapvX2v4A3BQ95PAHM+scXKnNalVfzOwCYLO7Lw660BZq9XdjZj8xs03AF4EfBFhrc9ri9+yw64j8bzdMbdmfsLSkD43pA2yq9/pwv46rv6HO/hsGM+sEnAb8td6hv/TGmjay7PD/BlOI7A6eCpwCPGFmg6MJHlNt1J97gB9HX/8YuIsmJtAMUmv7YmZZwPeJHEIJXRt9N7j794Hvm9n3gJuAH7Zxqc1qq75Et/V9oAZ4pC1rPBZt2Z+wHK0PZnYtcGt02VDgRTOrBja4+0U03a/j6m+HCxIie2F73H1M/YVmlgwsiL58jsg/rvV3vfsCW6LPS4C/RYNjnpnVEZkULYypiVvdH3cvrfe++4G/B1nwUbS2L0OAQcDi6F+svsBCM5vg7tsCrr0xbfG7Vt+jRGbJjnmQ0EZ9iQ7qfho4O4z/eNXT1t9NGBrtA4C7Pwg8CGBmrwLXuHtxvSYlwJn1XvclMpZSwvH0N+gBovbwAAZSb4AKeBu4OPrcgNFNvG8+kb2Ow4NOn4ounwn8KPr8BCK7iBbH/elVr81/Ao/Ha18atCkmhoPtAX03w+q1uRl4Mo77Mg1YDhTE8jsJ+neNGA22H28faHqwfQORIyudo8+7tKS/jdYVxhca41+ex4CtRObzKgGuJ/K/1tnA4ugv9g+aeG8hkYkm1wF389FMAGnAw9F1C4Gz4rw/DwFLgPeJ/C+sV7z2pUGbYmJ71lYQ381T0eXvE5mAr08c92Utkf90LYo+YnIGWoD9uSi6rSqgFHipPfaBRoIkuvy66HeyFri2uf4e7aEpUkREpFU66llbIiLSRhQkIiLSKgoSERFpFQWJiIi0ioJERERaRUEiCcHMKmL8eQ+Y2clttK1ai8zuu9TMnm9uVlwzyzezr7XFZ4u0BZ3+KwnBzCrcvVMbbi/FP5pgMFD1azezPwGr3f0nR2k/EPi7u4+MRX0izdEeiSQsMysws6fMbH70MTm6fIKZvW1m70V/Do8uv8bM/mpmzwNzzOxMM3vVzJ60yH00Hjl8b4bo8sLo84roxIqLzewdM+sRXT4k+nq+mf2ohXtNc/loAspOZvYvM1tokftDXBhtcwcwJLoX8/No229FP+d9M/t/bfjHKNIsBYkksl8D/+vupwCfBx6ILl8JTHH3sURm0/2feu+ZBHzJ3c+Kvh4LfB04GRgMTG7kc7KBd9x9NPA68OV6n//r6Oc3O19RdJ6ns4nMLgBQCVzk7uOI3APnrmiQfRdY5+5j3P1bZnYuMAyYAIwBxpvZlOY+T6StdMRJG6XjOAc4ud7MqLlmlgPkAX8ys2FEZjZNrfeel929/j0f5rl7CYCZLSIy19GbDT6nmo8mulwA/Ef0+SQ+upfDo8Avmqgzs962FxC5NwRE5jr6n2go1BHZU+nRyPvPjT7ei77uRCRYXm/i80TalIJEElkSMMndD9ZfaGa/Bf7t7hdFxxterbd6f4NtVNV7Xkvjf2cO+UeDjU21OZqD7j7GzPKIBNKNwG+I3H+kABjv7ofMrBjIaOT9BvzU3e87xs8VaRM6tCWJbA6R+3cAYGaHp9vOAzZHn18T4Oe/Q+SQGsBlzTV2971Ebqf7TTNLJVLn9miITAUGRJuWAzn13voScF30/hSYWR8z695GfRBploJEEkWWmZXUe3yDyD/KhdEB6OVEpv8H+BnwUzN7C0gOsKavA98ws3lAL2Bvc29w9/eIzOR6GZEbPxWaWRGRvZOV0TY7gbeipwv/3N3nEDl0NtfMlgBP8vGgEQmUTv8VCUj0jo0H3d3N7DLgcne/sLn3icQbjZGIBGc8cHf0TKs9hHD7YpFY0B6JiIi0isZIRESkVRQkIiLSKgoSERFpFQWJiIi0ioJERERa5f8HUaMTl/MjLvAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model training\n",
    "\n",
    "Time to run:\n",
    "\n",
    "* Full data set took about 13 hours using the Nvidia P1000\n",
    "* Full data set was predicted to take about 25 hours with the T4\n",
    "* 10% data took about 1 hour (1:08) using the Nvidia P1000\n",
    "* 10% data is predicted to take about 2.5 hour (actual 2:42) using the Nvidia GTX 1060\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.541368</td>\n",
       "      <td>2.339555</td>\n",
       "      <td>0.553032</td>\n",
       "      <td>2:42:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated new learner\n"
     ]
    }
   ],
   "source": [
    "# no idea how long nor how much resources this will take\n",
    "# not sure 1e-2 is the right learning rate; maybe 1e-1 or between 1e-2 and 1e-1\n",
    "# using t4\n",
    "# progress bar says this will take around 24 hours... ran for about 52 minutes\n",
    "# gpustat/nvidia-smi indicates currently only using about 5GB of GPU RAM\n",
    "# using p100\n",
    "# progress bar says this will take around 12 hours; took 13:16\n",
    "# at start GPU using about 5GB RAM\n",
    "# after about 8 hours GPU using about 7.5GB RAM.\n",
    "# looks like I could increase batch size...\n",
    "# with bs=64, still only seems to be using about 7GB GPU RAM after running for 15 minutes. \n",
    "# will check after a bit, but likely can increase batch size further\n",
    "\n",
    "if os.path.isfile(init_model_file):\n",
    "    learn.load(init_model_file)\n",
    "    print('loaded learner')\n",
    "else:\n",
    "    learn.fit_one_cycle(1, 5e-2, moms=(0.8,0.7))\n",
    "    learn.save(init_model_file)\n",
    "    print('generated new learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# continue from initial training - reload in case just want to continue processing from here\n",
    "# pytorch automatically appends .pth to the filename, you cannot provide it\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "learn.load(init_model_file)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos [ * * 2159 - 9 - 15 * * ] 2:53 xxup pm \\n  xxup chest (</td>\n",
       "      <td>xxup portable xxup ap ) xxmaj clip # [ * * xxmaj clip xxmaj number ( xxmaj radiology ) xxunk</td>\n",
       "      <td>xxup portable xxup ap ) xxmaj clip # [ * * xxmaj clip xxmaj number ( xxmaj radiology ) xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>restarted during her hospital \\n  stay . xxmaj she appeared to be fairly euvolemic . xxmaj she may \\n</td>\n",
       "      <td>require xxmaj lasix to be restarted during her rehab stay . \\n \\n  1 . xxmaj heme :</td>\n",
       "      <td>have \\n  monday . be started . the stay . . xxmaj xxmaj . xxmaj she : xxmaj hct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pacing wire is seen in the xxup ra \\n  and extending into the xxup rv . \\n \\n</td>\n",
       "      <td>xxup left xxup ventricle : xxmaj mild symmetric xxup lvh . xxmaj moderately dilated xxup lv cavity . \\n</td>\n",
       "      <td>xxup ventricle : xxmaj normal symmetric xxup lvh with xxmaj normal dilated xxup rv cavity . xxmaj xxmaj no global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>* * ] 05:08 xxup am \\n  [ * * 2141 - 2 - 10 * * ] 05:26</td>\n",
       "      <td>xxup am \\n  [ * * 2141 - 2 - 10 * * ] 11:17 xxup am \\n</td>\n",
       "      <td>xxup xxup am \\n  xxup * * xxmaj - 3 - 4 * * ] \\n  xxup pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxrep 78 _ \\n  xxup final xxup report \\n  xxup indication : 37-year - old woman with xxup</td>\n",
       "      <td>copd and increasing dyspnea on exertion in \\n  the setting of chest pain . xxmaj evaluate for pulmonary embolism</td>\n",
       "      <td>hiv , xxup dyspnea . exertion . the the lower of \\n  pain . \\n \\n  evaluate for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has been trained for 2 epochs already\n"
     ]
    }
   ],
   "source": [
    "prev_cycles = 0\n",
    "\n",
    "if os.path.isfile(cycles_file):\n",
    "    with open(cycles_file, 'rb') as f:\n",
    "        prev_cycles = pickle.load(f)\n",
    "print('This model has been trained for', prev_cycles, 'epochs already')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fine tune language model\n",
    "\n",
    "Performance notes w/P100 GPU:\n",
    "\n",
    "* at batch size of 128 takes about 1:14:00 per epoch; GPU usage is about 14GB; RAM usage is about 10GB\n",
    "* at batch size of 96 takes about 1:17:00 per epoch; GPU usage is about  9GB; RAM usage is about 10GB\n",
    "* at batch size of 48 takes about 1:30:00 per epoch; GPU usage is about  5GB; RAM usage is about 10GB\n",
    "\n",
    "With `learn.fit_one_cycle(8, 5e-3, moms=(0.8,0.7))` (8 cycles)\n",
    "* gets from about 62.7% accuracy to 67.6% accuracy\n",
    "* Total time: 9:54:16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded existing learner from /home/jupyter/mimic/mimic_lm_fine_tuned_2\n",
      "     1 addtional run of fit_one_cycle complete\n",
      "     2 addtional run of fit_one_cycle complete\n",
      "completed 2 new training epochs\n",
      "completed 4 total training epochs\n"
     ]
    }
   ],
   "source": [
    "# if want to continue training existing model, set to True\n",
    "# if want to start fresh from the initialized language model, set to False\n",
    "# also, make sure to remove any previously created saved states before changing\n",
    "# flag back to continue\n",
    "continue_flag = True\n",
    "########################################################\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "\n",
    "if continue_flag:\n",
    "    file = lm_base_file + str(prev_cycles)\n",
    "    learner_file = base_path/file\n",
    "    if os.path.isfile(str(learner_file) + '.pth'):\n",
    "        learn.load(learner_file)\n",
    "        print('loaded existing learner from', str(learner_file))\n",
    "    else:\n",
    "        # should not continue as could not find specified file\n",
    "        print('existing learner file not found')\n",
    "        assert(False)\n",
    "else:\n",
    "    prev_cycles = 0\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "########################################################\n",
    "# set this to how many additional cycles you want to run\n",
    "########################################################\n",
    "num_cycles = 2\n",
    "########################################################\n",
    "\n",
    "for n in range(num_cycles):\n",
    "    #learn.fit_one_cycle(1, 5e-3, moms=(0.8,0.7))\n",
    "    print('    ', n + 1, 'addtional run of fit_one_cycle complete')\n",
    "    file = lm_base_file + str(prev_cycles + n + 1)\n",
    "    learner_file = base_path/file\n",
    "    learn.save(learner_file)\n",
    "    with open(cycles_file, 'wb') as f:\n",
    "        pickle.dump(prev_cycles + n + 1, f)\n",
    "    release_mem()\n",
    "    \n",
    "print('completed', num_cycles, 'new training epochs')\n",
    "print('completed', num_cycles + prev_cycles, 'total training epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 9:54:16 <p><table style='width:375px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>1.926960</th>\n",
       "    <th>1.832659</th>\n",
       "    <th>0.627496</th>\n",
       "    <th>1:14:14</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.808083</th>\n",
       "    <th>1.755725</th>\n",
       "    <th>0.637424</th>\n",
       "    <th>1:14:15</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.747903</th>\n",
       "    <th>1.697741</th>\n",
       "    <th>0.645431</th>\n",
       "    <th>1:14:15</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>1.714081</th>\n",
       "    <th>1.652703</th>\n",
       "    <th>0.652703</th>\n",
       "    <th>1:14:19</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>1.637801</th>\n",
       "    <th>1.602961</th>\n",
       "    <th>0.660170</th>\n",
       "    <th>1:14:15</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>1.596906</th>\n",
       "    <th>1.553225</th>\n",
       "    <th>0.668557</th>\n",
       "    <th>1:14:14</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>1.572020</th>\n",
       "    <th>1.519172</th>\n",
       "    <th>0.674477</th>\n",
       "    <th>1:14:26</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>1.517364</th>\n",
       "    <th>1.510010</th>\n",
       "    <th>0.676342</th>\n",
       "    <th>1:14:14</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/mimic/mimic_lm_fine_tuned_3.pth']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_pattern = lm_base_file + '*'\n",
    "training_files = glob.glob(str(base_path/fn_pattern))\n",
    "training_files.sort()\n",
    "training_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to load the last file\n",
    "learn.load(training_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism \n",
      "  but showed no PE , but did show some pulmonary edema . She has had \n",
      "  some mild dyspnea on exertion but has improved . She was brought to the \n",
      "  ED for further evaluation\n",
      "For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism or dissection . \n",
      "  She was extubated today and given 1 unit of prbcs for Hct of 24 . She is \n",
      "  afebrile , HR in the 120s , BP stable . She is\n"
     ]
    }
   ],
   "source": [
    "# test the language generation capabilities of this model (not the point, but is interesting)\n",
    "TEXT = \"For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2\n",
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder(enc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the encoder:\n",
    "\n",
    "```python\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "learn.load_encoder(enc_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now based on our language model, train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_file = 'mimic_cl.pickle'\n",
    "filename = base_path/class_file\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    data_cl = load_data(base_path, file, bs=bs)\n",
    "else:\n",
    "    data_cl = (TextList.from_df(df, cols='', vocab=data_lm.vocab)\n",
    "               #grab all the text files in path\n",
    "               .split_by_folder(valid='test')\n",
    "               #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "               .label_from_folder(classes=['neg', 'pos'])\n",
    "               #label them all with their folders\n",
    "               .databunch(bs=bs))\n",
    "\n",
    "data_cl.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.CATEGORY.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1676"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.DESCRIPTION.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(filename):\n",
    "    data_lm = load_data(base_path, file, bs=bs)\n",
    "else:\n",
    "    data_lm = (TextList.from_df(df, 'texts.csv', cols='TEXT')\n",
    "               #df has several columns; actual text is in column TEXT\n",
    "               .split_by_rand_pct(valid_pct=0.1, seed=seed)\n",
    "               #We randomly split and keep 10% for validation\n",
    "               .label_from_df(cols='DESCRIPTION')\n",
    "               #We want to do a language model so we label accordingly\n",
    "               .databunch(bs=bs))\n",
    "    data_lm.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the version from the original example\n",
    "```python\n",
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs))\n",
    "\n",
    "data_clas.save('data_clas.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_cl, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder(enc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change learning rate based on results from the above plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
