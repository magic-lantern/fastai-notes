{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using FAST.AI for NLP\n",
    "\n",
    "Exploring the MIMIC III data set medical notes.\n",
    "\n",
    "Tried working with the full dataset, but almost every training step takes many hours (~13 for initial training), predicted 14+ per epoch for fine tuning.\n",
    "\n",
    "Instead will try to work with just 10% sample... Not sure that will work though\n",
    "\n",
    "A few notes:\n",
    "* See https://docs.fast.ai/text.transform.html#Tokenizer for details on what various artificial tokens (e.g xxup, xxmaj, etc.) mean\n",
    "* To view nicely formatted documentation on the fastai library, run commands like: ` doc(learn.lr_find)`\n",
    "\n",
    "### To Do:\n",
    "* need to evalate how changing the learning rate would alter training time\n",
    "* need to evalate how changing the learning rate would alter accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to verify that Torch can find and use your GPU, run the following code:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next cells can be used to get an idea of the speed up provided by a GPU for some operations (from https://course.fast.ai/gpu_tutorial.html)\n",
    "```python\n",
    "import torch\n",
    "t_cpu = torch.rand(500,500,500)\n",
    "%timeit t_cpu @ t_cpu\n",
    "# separate cell \n",
    "t_gpu = torch.rand(500,500,500).cuda()\n",
    "%timeit t_gpu @ t_gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data set too large to work with in reasonable time due to limted GPU resources\n",
    "pct_data_sample = 0.01\n",
    "# how much to hold out for validation\n",
    "valid_pct = 0.1\n",
    "\n",
    "# pandas doesn't understand ~, so provide full path\n",
    "base_path = Path('/home/seth/mimic')\n",
    "\n",
    "# files used during processing - all aggregated here\n",
    "notes_file = base_path/'noteevents.pickle'\n",
    "lm_file = 'mimic_lm.pickle' # actual file is at base_path/lm_file but due to fastai function, have to pass file name separately\n",
    "init_model_file = base_path/'mimic_fit_head'\n",
    "cycles_file = base_path/'num_iterations.pickle'\n",
    "lm_base_file = 'mimic_lm_fine_tuned_'\n",
    "enc_file = 'mimic_fine_tuned_enc'\n",
    "class_file = 'mimic_cl.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this doesn't free memory, can restart Python kernel.\n",
    "# if that still doesn't work, try OS items mentioned here: https://docs.fast.ai/dev/gpu.html\n",
    "def release_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see what has already been imported\n",
    "#whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Random Number seed for repeatability; set Batch Size to control GPU memory\n",
    "\n",
    "See **\"Performance notes\"** section below for how setting batch size impacts GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# previously used 48; worked fine but never seemed to use even half of GPU memory; 64 still on the small side\n",
    "bs=48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While parsing a CSV and converting to a dataframe is pretty fast, loading a pickle file is much faster.\n",
    "\n",
    "For load time and size comparison:\n",
    "* `NOTEEVENTS.csv` is ~ 3.8GB in size\n",
    "  ```\n",
    "  CPU times: user 51.2 s, sys: 17.6 s, total: 1min 8s\n",
    "  Wall time: 1min 47s\n",
    "  ```\n",
    "* `noteevents.pickle` is ~ 3.7 GB in size\n",
    "  ```\n",
    "  CPU times: user 2.28 s, sys: 3.98 s, total: 6.26 s\n",
    "  Wall time: 6.26 s\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noteevnt pickle file\n",
      "CPU times: user 2.59 s, sys: 1.1 s, total: 3.69 s\n",
      "Wall time: 3.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "orig_df = pd.DataFrame()\n",
    "if os.path.isfile(notes_file):\n",
    "    print('Loading noteevnt pickle file')\n",
    "    orig_df = pd.read_pickle(notes_file)\n",
    "else:\n",
    "    print('Could not find noteevent pickle file; creating it')\n",
    "    # run this the first time to covert CSV to Pickle file\n",
    "    orig_df = pd.read_csv(base_path/'NOTEEVENTS.csv', low_memory=False, memory_map=True)\n",
    "    orig_df.to_pickle(notes_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to data set size and performance reasons, working with a 10% sample. Use same random see to get same results from subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orig_df.sample(frac=pct_data_sample, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to free up some memory\n",
    "# orig_df = None\n",
    "# del orig_df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: 93 MB\n"
     ]
    }
   ],
   "source": [
    "from pympler import asizeof\n",
    "print('df:', int(asizeof.asizeof(df) / 1024 / 1024), 'MB')\n",
    "#print('orig_df:', asizeof.asizeof(orig_df))\n",
    "#print('data_lm:', asizeof.asizeof(data_lm, detail=1))\n",
    "#print asizeof.asized(obj, detail=1).format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1292716</th>\n",
       "      <td>1295263</td>\n",
       "      <td>2549</td>\n",
       "      <td>159440.0</td>\n",
       "      <td>2132-04-02</td>\n",
       "      <td>2132-04-02 13:09:00</td>\n",
       "      <td>2132-04-02 13:35:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>18566.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCU NSG TRANSFER SUMMARY UPDATE: RESP FAILURE\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160271</th>\n",
       "      <td>1175599</td>\n",
       "      <td>29621</td>\n",
       "      <td>190624.0</td>\n",
       "      <td>2149-02-23</td>\n",
       "      <td>2149-02-23 03:27:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[**2149-2-23**] 3:27 AM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549380</th>\n",
       "      <td>1555118</td>\n",
       "      <td>22384</td>\n",
       "      <td>142591.0</td>\n",
       "      <td>2185-03-26</td>\n",
       "      <td>2185-03-26 17:58:00</td>\n",
       "      <td>2185-03-26 18:01:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>16985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respiratory Care\\nPt remains intubated (#7.5 E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>5743</td>\n",
       "      <td>690</td>\n",
       "      <td>152820.0</td>\n",
       "      <td>2182-09-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2182-9-12**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014768</th>\n",
       "      <td>2023163</td>\n",
       "      <td>25560</td>\n",
       "      <td>156143.0</td>\n",
       "      <td>2154-11-18</td>\n",
       "      <td>2154-11-18 10:44:00</td>\n",
       "      <td>2154-11-18 17:08:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>16888.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neonatology\\nOn exam pink active non-dysmorphi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE            CHARTTIME  \\\n",
       "1292716  1295263        2549  159440.0  2132-04-02  2132-04-02 13:09:00   \n",
       "1160271  1175599       29621  190624.0  2149-02-23  2149-02-23 03:27:00   \n",
       "1549380  1555118       22384  142591.0  2185-03-26  2185-03-26 17:58:00   \n",
       "7474        5743         690  152820.0  2182-09-14                  NaN   \n",
       "2014768  2023163       25560  156143.0  2154-11-18  2154-11-18 10:44:00   \n",
       "\n",
       "                   STORETIME           CATEGORY          DESCRIPTION     CGID  \\\n",
       "1292716  2132-04-02 13:35:00      Nursing/other               Report  18566.0   \n",
       "1160271                  NaN          Radiology  CHEST (PORTABLE AP)      NaN   \n",
       "1549380  2185-03-26 18:01:00      Nursing/other               Report  16985.0   \n",
       "7474                     NaN  Discharge summary               Report      NaN   \n",
       "2014768  2154-11-18 17:08:00      Nursing/other               Report  16888.0   \n",
       "\n",
       "         ISERROR                                               TEXT  \n",
       "1292716      NaN  CCU NSG TRANSFER SUMMARY UPDATE: RESP FAILURE\\...  \n",
       "1160271      NaN  [**2149-2-23**] 3:27 AM\\n CHEST (PORTABLE AP) ...  \n",
       "1549380      NaN  Respiratory Care\\nPt remains intubated (#7.5 E...  \n",
       "7474         NaN  Admission Date:  [**2182-9-12**]       Dischar...  \n",
       "2014768      NaN  Neonatology\\nOn exam pink active non-dysmorphi...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROW_ID           int64\n",
       "SUBJECT_ID       int64\n",
       "HADM_ID        float64\n",
       "CHARTDATE       object\n",
       "CHARTTIME       object\n",
       "STORETIME       object\n",
       "CATEGORY        object\n",
       "DESCRIPTION     object\n",
       "CGID           float64\n",
       "ISERROR        float64\n",
       "TEXT            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20832, 11)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test sets; using same random seed so subsequent runs will generate same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 1./3\n",
    "train, test = train_test_split(df, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13888, 11)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6944, 11)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to build initial version of language model; If running with full dataset, requires a **LOT** of RAM; using a **LOT** of CPU helps it to happen quickly as well\n",
    "\n",
    "Questions:\n",
    "\n",
    "* why does this only seem to use CPU? (applies to both both textclasdatabunch and textlist)\n",
    "* for 100% of the mimic noteevents data:\n",
    "  * run out of memory at 32 GB, error at 52 GB, trying 72GB now... got down to only 440MB free; if crash again, increase memory\n",
    "  * now at 20vCPU and 128GB RAM; ok up to 93%; got down to 22GB available\n",
    "  * succeeded with 20CPU and 128GB RAM...\n",
    "* try smaller batch size? will that reduce memory requirements?\n",
    "* with 10% dataset sample, it seems I could get by with perhaps 32GB system RAM\n",
    "\n",
    "For comparison:\n",
    "* 10% langauge model is ~ 1.2 GB in size\n",
    "  * Time to load existing language model:\n",
    "    ```\n",
    "    CPU times: user 3.29 s, sys: 844 ms, total: 4.14 s\n",
    "    Wall time: 12.6 s\n",
    "    ```\n",
    "  * Time to build language model:\n",
    "    ```\n",
    "    CPU times: user 36.9 s, sys: 8.56 s, total: 45.4 s\n",
    "    Wall time: 3min 27s\n",
    "    ```\n",
    "* 100% language model is...\n",
    "  * Time to load existing language model:\n",
    "  * Time to build language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing langauge model\n",
      "CPU times: user 234 ms, sys: 52.1 ms, total: 286 ms\n",
      "Wall time: 285 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tmpfile = base_path/lm_file\n",
    "\n",
    "if os.path.isfile(tmpfile):\n",
    "    print('loading existing langauge model')\n",
    "    data_lm = load_data(base_path, lm_file, bs=bs)\n",
    "else:\n",
    "    print('creating new language model')\n",
    "    data_lm = (TextList.from_df(df, 'texts.csv', cols='TEXT')\n",
    "               #df has several columns; actual text is in column TEXT\n",
    "               .split_by_rand_pct(valid_pct=valid_pct, seed=seed)\n",
    "               #We randomly split and keep 10% for validation\n",
    "               .label_for_lm()\n",
    "               #We want to do a language model so we label accordingly\n",
    "               .databunch(bs=bs))\n",
    "    data_lm.save(tmpfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If need to view more data, run appropriate line to make display wider/show more columns...\n",
    "```python\n",
    "# default 20\n",
    "pd.get_option('display.max_columns')\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_columns', None) # show all\n",
    "# default 50\n",
    "pd.get_option('display.max_colwidth')\n",
    "pd.set_option('display.max_colwidth', -1) # show all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pacs . xxmaj bp went back to 150 / 80 . xxup hr varies between 80s to low 90s at rest up to 1-teens with activity . xxup bp varies more widely between 1-teens / 70s at rest up to 170 / 90s with activity . xxmaj she continues on dilt 90 mg po qid . xxmaj she was xxup k+ replaced today . \\n  xxup resp : xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>inr:17.6 / 35.9 / 1.6 , xxup ck / xxup ckmb / \\n  xxmaj troponin - xxup xxunk / 6 / 0.03 , xxmaj differential - xxmaj neuts:79.9 % , xxmaj lymph:10.8 % , \\n  xxmaj mono:5.8 % , xxmaj eos:3.3 % , xxmaj ca++:8.0 mg / dl , xxmaj mg++:2.0 mg / dl , xxup po4:1.8 mg / dl \\n  xxmaj assessment and xxmaj plan \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[ * * xxmaj last xxmaj name ( namepattern1 ) 1782 * * ] at 11:15 a.m. on [ * * 2181 - 2 - 20 * * ] . \\n \\n  xxbos xxmaj renal failure , acute ( xxmaj acute renal failure , xxup arf ) \\n  xxmaj assessment : \\n  xxmaj pt . anuric s / p nephrectomy . \\n  xxmaj action : \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>xxmaj name ( xxup ni ) 87 * * ] . \\n \\n  p : xxmaj fully awaken and extubate . xxmaj restart cardiac meds as soon as pt able to take po . xxmaj restart oral diabetic meds when pt taking food . xxmaj maintain c - collar at all times , under head pillow when supine . ? transfuse xxup rbc in setting of volume dependent hypotension</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>and suppport as needed . \\n \\n  xxup fen : xxmaj weight 848 g , xxunk . tf=130cc / kg / day . xxmaj enteral feeds \\n  presently at 120cc / kg / day of xxup xxunk 20cc xxmaj q4hrs , xxup pg , gavaged \\n  over 40 minutes and tol well . xxmaj no spits . xxmaj dstick 61 . xxup ivf off \\n  at</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()\n",
    "# how to look at original version of text\n",
    "#df[df['TEXT'].str.contains('being paralyzed were discussed', case=False)].TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as of June 2019, this automatically loads and initializes the model based on WT103 from\n",
    "# https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz; will auto download if not already on disk\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Learning rate graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEGCAYAAABPdROvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxU5b3H8c8v+54AWYCw75uCEFBEUVxQq3XfqrVVW5FetXbRe3tv7XLrta3dtdZa69Jq626pWhW1WhdAwKBsAsoqO4SdAElI8rt/ZNA0JCQwOTnJ5Pt+veaVmXOemfk9TMh3znnOeY65OyIiIkcqLuwCRESkbVOQiIhIVBQkIiISFQWJiIhERUEiIiJRSQi7gMOVm5vrvXr1CrsMEZE2Zc6cOVvcPS+I125zQdKrVy+Ki4vDLkNEpE0xs0+Cem3t2hIRkagoSEREJCoKEhERiYqCREREoqIgERGRqChIREQkKgoSERGJioKkFfl4024eeGcF76/ejqb3F5G2ItATEs0sB3gAGAY4cK27v1trvQF3AZ8D9gJXu/v7QdbU2mzfU8Hz89bz7Ptrmb9256fLe3ZK47zhXTnvmEL65mWEWKGIyKEFfWb7XcBUd7/YzJKAtDrrzwL6R27HAr+P/Ix5W0rLueeNZTw2azUVVdUM6ZLF988ZwqmD85m1chvPzV3Hb/+1jLvfWMbFo7rxw3OHkpHc5iYiEJF2ILC/TGaWBYwHrgZw9wqgok6z84BHvGY/zkwzyzGzLu6+Iai6wranvJIHp63kD28tp6yymktGdeNLY3sxpGvWp216dkrn0qLubNpVxsPTV3H/28uZvXIbv75sOKN6dgyxehGRgwX5FbcPUAI8bGbDgTnAze6+p1abQmBNrcdrI8v+LUjMbBIwCaBHjx4Blhyc6mrn6Tlr+PkrH7OltJwzhhZw6xmD6Jff8G6rgqwUvnPWIE4dnM83npjLJfe9y42n9OfGCf1IStDwloi0DhbUoK6ZFQEzgXHuPsvM7gJ2ufv3arV5EfiJu0+LPH4d+E93n9PQ6xYVFXlbm7Txg9Xb+eHzHzJv7U5G9sjhu2cPPuwti11l+/nBcx8y5YN1ZCYnMK5fLhMG5XHywHwKslICqlxEYoWZzXH3oiBeO8gtkrXAWnefFXn8DPCdetp0r/W4G7A+wJpaVMnucu6cuoRn5qwlPzOZX182nPNHFFJzjMHhyUpJ5NeXjeCCYwp5eeEG/rWkhKkfbgQgJy2RjOQEMpITyExJoKhXR75+Sn9Sk+Kbu0siIgcJLEjcfaOZrTGzge7+EXAqsKhOs+eBG83sCWoG2XfGwvhI2f4qHp6+it/9axnllVVcf1Ifbjqlf7MMlo8fkMf4AXm4Ox9t2s1bH5Wwbsc+Sssq2V1eyY69Ffz+zeW8tGADd150NMf16dQMPRIRaVjQhwHdBPw1csTWCuAaM5sM4O73AS9Rc+jvMmoO/70m4HoC5e5MXbiRH7+8mDXb9nHa4AL+53OD6BPA4btmxqDOWQzqnHXQuhnLt/CdZxdw+f0z+dLYnvzXmYNI1xFfIhKQwMZIgtIax0jKK6t4cf4G/jRjFfPX7mRgQSbfO2cIJ/TPDa2mvRWV/PyVj/jTjFV0SEvivBFduWhkN4Z2zTqiXWutSWVVNbNXbmPJxt0sKyll+eZSVm/by7DCbM4fUcipg/NJSdRuPZHaghwjUZBEYcPOfTw2azWPz17NltIK+uVn8JUTenPJqG4kxLeOo6rmfLKdB95ZweuLN1NRVc2gzpl8fnhXjumew9DCbLJTE8Muscm2lJbz5Htr+OvMT1i/swyA7NRE+uVn0DUnlVkrtrJ5dzmZyQmcMawzPTqmUV5ZRdn+asorq4g3IzUpgbSkeNKS4unVKZ0T+ucqdKRdUJDUEnaQVFRW88aSTTz53hre+rgEB04dlM/Vx/dmXL9Orfbb/o69Fbwwbz3PvL+OeWt2fLq8Z6c0jumew4Uju3FCv1zi4lpX/VXVzqwVW3mqeA0vLdhIRVU14/p14ovH9mRM7450TE/69N+8qtqZuWIrf/9gHS8v3EhpeSUJcUZyQhzJifFUu7O3vIqKqupPXz89KZ6TB+Vz1rDOTBiYr12AErMUJLW0dJBUVlWzdHMpC9btZP7aHby8YCNb91TQOSuFi0d149Ki7vToVPeE/dZt+54KFqzbyYJ1O1m4biczV2xl+979dO+YymVF3blwZDfyM5MD26paUVLKmu37GFCQQeeslIPCt7q65kCCv3+wjufmrmfjrjIykxO4cGQhV43tSb/8zEbfo6racfd6+1BZVc2eiirmrdnByws38tqijWwprSApPo4xvTty8sA8Th6YR9+8jFb7xUDkcClIammpINlaWs4tT8/j3RVbKdtf8w02PSmeE/vncdno7owfkEd8K/v2fqTKK6t45cNNPDF7NTOWb/10eZxBckI8KYlx5GYkU5CVQn5WMp2zUuidm86Agkz6F2SQltT4t/i9FZW8tGAjT723htmrtn26PDs1kYEFmeRnJbNpVxkbdpaxaVcZ+6uchDjjpAF5nH9MIacPKQhsF1RVtfPeqm28vngTb35UwtLNpQB0yU7h6G7ZHN0th6MKsxnUOZPkxHgS4oyEeCMxLq7VbcGJNERBUsuRBom7s6W0grzM5Ebbrtuxj6semMX6nfu4YkxPju6WzbDCbHrnpsdMeDRk5ZY9vL54E3srqqiorBlb2Le/ipLd5WzaVc7mXWVs3l1OZfVnvzfdOqRSmJNKbmYyeRnJ5GYkUe2wY+9+duytYPveCopXbWd3eSW9c9O5bHR3hnfLYdnm3SzeuJuPNu5ma2k5BVkpdMlOoUtOKr06pXHa4AI6ZTT+eTW3dTv28eZHm5m5YhsL1+1k5ZY99baLjzMGdc7kmB45jOjegRHds8nPSiEjKUEBI62OgqSWIw2S1xZt4qbH3+e6E/tw/Ul9GzynY+mm3Vz14Gz2VlTy0NWjKeqlua3qqqyq5pNte1m6aTcfbypl6eZSNu0sY0tpOSWl5ewuqwQgIzmB7NREOqQnMrAgi8tGd2d0rw5tbnfRzn37+XDdTpaVlFJRWU1VtVNZ7ewuq2Thup3MW7OD3eWVn7Y3q+l7VkoihTmp9MpNo1duOr07pTO0azbdO6a2uX8DafsUJLUcaZCs2baXO6cu4R/zN5Cbkcy3Jw7g0qLu/7aF8cHq7Vzzp/dIjI/jkWvHMLjLwedoSOPK9lcRZ9Zu5gOrrnaWl9SMo23bU8Guskp27dvPzn37Wbt9Lyu37GVLafmn7fMykxndqwOjenb8dCxGJGgKklqiHSN5f/V27nhxMXM+2U7v3HSyUhPZvqeC7Xsq2F1eSY+OaTz6lTH07JTejFVLe7e7bD+rtuxl7todzFm1jfdWbWfdjn0AjOnVkctGd+dzR3XRtDYSGAVJLc0x2O7uvLxwI4+8u4qkhHg6piWSk5ZEXmYylxZ1b9I4iki01u/Yx/Pz1vPke2tYuWUPmSkJXHhMIVeN7XXIWaFFjoSCpJawzyMRaW7uzqyV23hi9upPz5UZPyCPq4/vyckD8jVwL81CQVKLgkRi2ZbSch6ftZpHZ37C5t3lDCzI5JeXDmdYYXbYpUkbF2SQtI/RUJE2IjcjmZtO7c/075zCXZePYMe+Ci64dzq/f3M5VdVt60uftB8KEpFWKDE+jvNGFDL15vGcNriAO6cu4Yo/zvx0gF6kNVGQiLRiHdKTuPfKkfz84qNZuG4nZ/3mbd76uCTsskT+jYJEpJUzMy4p6s5LN59I15xUrnl4Nve/vZy2Nr4psUtBItJG9OyUzrNfO54zhnbmxy8t4VtPzaNsf1XYZYkoSETakvTkBO69ciTfOn0AUz5Yx2V/eJdNu8rCLkvauUCDxMxWmdkCM5trZgcds2tmHcxsipnNN7PZZjYsyHpEYoGZ8fVT+3P/VaNYurmU8383nUXrd4VdlrRjLbFFMsHdRzRw/PL/AHPd/WjgS8BdLVCPSEyYOLQzT08eC8DF983g9cWbQq5I2quwd20NAV4HcPclQC8zKwi3JJG2Y2jXbP5+wzj65mVw3SPFPDhtpQbhpcUFHSQOvGpmc8xsUj3r5wEXApjZGKAn0K1uIzObZGbFZlZcUqJDH0VqK8hK4cnrj+O0wQXc/o9F3PzEXHaV7Q+7LGlHgg6Sce4+EjgLuMHMxtdZ/1Ogg5nNBW4CPgAq67TB3e939yJ3L8rLywu4ZJG2Jy0pgfu+OIpbJg7gxQUbOPvud/hg9fawy5J2ItAgcff1kZ+bgSnAmDrrd7n7Ne4+gpoxkjxgZZA1icSquDjjxlP689T1x1FdDZfc9y6/f3M51ZpaRQIWWJCYWbqZZR64D0wEFtZpk2NmSZGHXwXedncdfiIShVE9O/LSzSdyxtDO3Dl1CTc+/r7ON5FA1X+92eZRAEyJXFI0AXjM3aea2WQAd78PGAw8YmZVwCLgKwHWI9JuZKcmcs8VxzDinRzueGkxW3bP5v4vjSInLanxJ4scJk0jLxLjXpi3nm8/NY8endL487VjKMxJDbskCYGmkReRI/b54V3587Vj2LSrjAt+N53FG7T3WJqXgkSkHRjbtxPPfu144uOML/xxJgvX7Qy7JIkhChKRdmJAQSZPThpLelICV/xxJvPX7gi7JIkRChKRdqRHpzSemHQcWamJXPnALOauUZhI9BQkIu1M945pPHn9WDqkJXHVA7OY88m2sEuSNk5BItIOFeak8uT1x5GbmcyVD8zijSWa8FGOnIJEpJ3qkp3K05PH0j8/k+semcPTxWvCLknaKAWJSDuWm5HM45OOY2yfTtz6zHx+/6Yu4SuHT0Ei0s5lJCfw0NWj+fzwrtw5dQn/+8IiKquqwy5L2pAgp0gRkTYiKSGOuy4bQUFmMg9MW8myzaXcc8UxmlJFmkRbJCIC1MwefNs5Q/jZRUcza+VWzvvddJZu2h12WdIGKEhE5N9cOro7T0w6jj3lVVxw7wwd0SWNUpCIyEFG9ezICzeNo3duOtc/OodpS7eEXZK0YgoSEalXl+xU/vLVY+mbl8H1jxZrShVpkIJERBqUnZrII9eOoUN6Etc8/B4rt+wJuyRphRQkInJI+VkpPPqVYwG46sFZbNpVFnJF0tooSESkUb1z0/nTNWPYvqeCqx6cxWaFidQSaJCY2SozW2Bmc83soMsamlm2mb1gZvPM7EMzuybIekTkyB3VLZs/frmItdv3cdF9M1il3VwS0RJbJBPcfUQDl3i8AVjk7sOBk4FfmpnOgBJppY7vm8vj1x1HaVklF983QxfIEiD8XVsOZJqZARnANqAy3JJE5FCGd8/hma8dT3JCPJffP5MZy3VocHsXdJA48KqZzTGzSfWsvwcYDKwHFgA3u/tBk/yY2SQzKzaz4pKSkmArFpFG9c3L4NmvHU/XnBSufvg9Fq3XdeDbs6CDZJy7jwTOAm4ws/F11p8BzAW6AiOAe8wsq+6LuPv97l7k7kV5eXkBlywiTdE5O4XHrjuOnNREbnz8ffZWaGdCexVokLj7+sjPzcAUYEydJtcAf/May4CVwKAgaxKR5pObkcxvLhvByi17+MFzH4ZdjoQksCAxs3QzyzxwH5gILKzTbDVwaqRNATAQWBFUTSLS/I7vl8uNE/rx9Jy1/P2DdWGXIyEIcoukAJhmZvOA2cCL7j7VzCab2eRIm9uB481sAfA68F/urpE7kTbm5lP7U9SzA9+dskCHBbdD1tauhlZUVOTFxQedkiIiIVu3Yx+fu+sdundM5dnIUV3SepjZnAZOw4ha2If/ikiMKMxJ5WcXH83Cdbv4+dSPwi5HWpCCRESazRlDO3PVcT15YNpK3vxoc9jlSAtRkIhIs/ru2YMZWJDJLU/Po2R3edjlSAtQkIhIs0pJjOfuLxzD7rJKbnl6HtXVbWscVg6fgkREmt3AzpncdvZg3vq4hIemrwy7HAmYgkREAvHF43py+pAC7py6RJM7xjgFiYgEwsz42UVH0yk9mZuf+IB9FVVhlyQBUZCISGA6pCfxq0uHs2LLHm5/cVHY5UhAFCQiEqjj++UyaXwfHpu1mqkLN4ZdjgRAQSIigfv26QM5qjCb7/xtPht36jK9sUZBIiKBS0qI4zeXj6B8fzXfemquDgmOMQoSEWkRffMy+MHnhzBj+VbufXNZ2OVIM1KQiEiLuWx0d84d3pVfvfYx05dpou9YoSARkRZjZvzkwqPok5fB1x//QOMlMUJBIiItKj05gfu+OJJ9+6u44bH32V9VHXZJEiUFiYi0uH75mfz0oqOZ88l2fvLSkrDLkSgpSEQkFOcO78qXx/bkoekrdX5JGxdokJjZKjNbYGZzzeygyxqa2a2RdXPNbKGZVZlZxyBrEpHW47tnD2Fo1yy+/9xCdpXtD7scOUItsUUywd1H1HeJR3f/eWTdCOC/gbfcfVsL1CQirUBSQhw/ufAotpSW84tXdFXFtqo17dr6AvB42EWISMs6ulsOXxrbi0dnfsIHq7eHXY4cgaCDxIFXzWyOmU1qqJGZpQFnAs82sH6SmRWbWXFJSUlApYpIWL49cQAFmSn8z5SFVOoorjYn6CAZ5+4jgbOAG8xsfAPtPg9Mb2i3lrvf7+5F7l6Ul5cXVK0iEpLMlER+eO5QFm/YxcPTV4VdjhymQIPE3ddHfm4GpgBjGmh6OdqtJdKunTG0gNMG5/Or1z5m7fa9YZcjhyGwIDGzdDPLPHAfmAgsrKddNnAS8FxQtYhI62dm/O95wzCD7z/3Ie6a2LGtCHKLpACYZmbzgNnAi+4+1cwmm9nkWu0uAF519z0B1iIibUBhTirfPG0AbyzZzCsf6tyStsLaWuoXFRV5cfFBp6SISIyorKrm8/dMZ/ueCv757ZPISE4Iu6SYYGZz6jsNozm0psN/RURIiI/jxxcMY9PuMn75qs4taQsUJCLS6hzTowNXHtuDP89YxcJ1O8MuRxqhIBGRVunWMwbRKSOZ/5mygCpdUbFVU5CISKuUnZrI984Zwvy1O3n03VVhlyOH0KQgMbO+ZpYcuX+ymX3dzHKCLU1E2rvPH92FE/rlctfrSyktrwy7HGlAU7dIngWqzKwf8CDQG3gssKpERKg5t+TWMwayfe9+/jR9ZdjlSAOaGiTV7l5JzTkfv3H3bwJdgitLRKTG8O45nDY4n/vfXqGp5luppgbJfjP7AvBl4B+RZYnBlCQi8u++cdoAdpVV8uA72ippjZoaJNcAY4E73H2lmfUG/hJcWSIinxlWmM2ZQzvz0LSV7NhbEXY5UkeTgsTdF7n71939cTPrAGS6+08Drk1E5FPfOL0/pRWVPKCtklanqUdtvWlmWZHL4M4DHjazXwVbmojIZwZ1zuLso7rw8PSVbNujrZLWpKm7trLdfRdwIfCwu48CTguuLBGRg33jtP7s21/FH95aHnYpUktTgyTBzLoAl/LZYLuISIvql5/JeSMK+fO7q9i0qyzsciSiqUHyI+AVYLm7v2dmfYClwZUlIlK/b50+gKpq5zf/1J+g1qKpg+1Pu/vR7v61yOMV7n5RsKWJiByse8c0rjy2J08Vr2F5SWnY5QhNH2zvZmZTzGyzmW0ys2fNrFvQxYmI1OfGU/qRkhCnaeZbiabu2noYeB7oChQCL0SWiYi0uNyMZL56Yh9eWrCReWt2hF1Ou9fUIMlz94fdvTJy+xOQ19iTzGyVmS0ws7lmVu9lDSOTQM41sw/N7K3DqF1E2rHrxvehU3oSd05douu7h6ypQbLFzL5oZvGR2xeBrU187gR3H1HfJR4jMwjfC5zr7kOBS5r4miLSzmUkJ3DjKf2YsXwr7yzdEnY57VpTg+Raag793QhsAC6mZtqUaF0B/M3dVwO4++ZmeE0RaSeuOLYH3TqkaqskZE09amu1u5/r7nnunu/u51NzcmKjTwVeNbM5ZjapnvUDgA6RM+fnmNmX6nsRM5tkZsVmVlxSUtKUkkWkHUhOiOfrp/bnw/W7eFtbJaGJ5gqJ32pCm3HuPhI4C7jBzMbXWZ8AjALOBs4AvmdmA+q+iLvf7+5F7l6Ul9fo0IyItCPnjyikICtZZ7uHKJogscYauPv6yM/NwBRgTJ0ma4Gp7r7H3bcAbwPDo6hJRNqZpIQ4rh3XmxnLt7Jg7c6wy2mXogmSQ+6QNLN0M8s8cB+YCCys0+w54EQzSzCzNOBYYHEUNYlIO/SFY3uQmZzAH97WVkkYEg610sx2U39gGJDayGsXAFPM7MD7PObuU81sMoC73+fui81sKjAfqAYecPe6YSMickhZKYlccWwP/vjOCtZs20v3jmlhl9SuWFs70qGoqMiLi+s9JUVE2rGNO8s48WdvcMWYHvzvecPCLqfVMbM59Z2G0Ryi2bUlItJqdM5O4fwRhTxZvEbXK2lhChIRiRmTxvehbH81j777SdiltCsKEhGJGf0LMjl1UD5/fncVZfurwi6n3VCQiEhMuW58H7btqeBv768Lu5R2Q0EiIjHl2N4dGVaYxYPTVlBd3bYOJmqrFCQiElPMjK+e0IflJXt462NNqdQSFCQiEnM+d1QXOmel8MC0FWGX0i4oSEQk5iQlxPHl43sxfdlWFm/YFXY5MU9BIiIx6YoxPUhNjOfBaSvDLiXmKUhEJCZlpyVyaVE3npu7js27ysIuJ6YpSEQkZl0zrjeV1c6jM3WCYpAUJCISs3rlpnPa4AL+MvMT9lXoBMWgKEhEJKZdP74P2/fu58/vrgq7lJilIBGRmFbUqyMTBuZx77+WsXPv/rDLiUkKEhGJebeeMYhdZZW68FVAFCQiEvOGdM3ivBFdeWj6Sh3BFQAFiYi0C98+fSCVVc5dry8Nu5SYE2iQmNkqM1tgZnPN7KDLGprZyWa2M7J+rpl9P8h6RKT96tEpjSuO7cET761h5ZY9YZcTU1pii2SCu484xCUe34msH+HuP2qBekSknbrxlH4kxcfxq9c+DruUmKJdWyLSbuRnpvCVE3rzwrz1LFi7M+xyYkbQQeLAq2Y2x8wmNdBmrJnNM7OXzWxofQ3MbJKZFZtZcUmJpoUWkSM36aQ+dEpP4vYXF+Gu65U0h6CDZJy7jwTOAm4ws/F11r8P9HT34cBvgb/X9yLufr+7F7l7UV5eXrAVi0hMy0pJ5JunD2D2ym288uHGsMuJCYEGibuvj/zcDEwBxtRZv8vdSyP3XwISzSw3yJpERC4f3Z2BBZnc8dJiyis1dUq0AgsSM0s3s8wD94GJwMI6bTqbmUXuj4nUszWomkREABLi47jtnMGs2baPh6evCrucNi/ILZICYJqZzQNmAy+6+1Qzm2xmkyNtLgYWRtrcDVzu2mkpIi3gxP55nDoon3veWEbJ7vKwy2nTrK393S4qKvLi4oNOSREROWzLS0o549dvc0lRd35y4VFhlxMoM5tziNMwoqLDf0Wk3eqbl8GXxvbiyfdWs2i9Lsl7pBQkItKu3Xxqf7JSE/k/HQ58xBQkItKuZacl8s3TBjBj+Vb+uXhz2OW0SQoSEWn3rji2B33z0rnjxUVUVFaHXU6boyARkXYvMT6O284Zwqqte3nk3VVhl9PmKEhERIAJA/M5aUAed72+lG17KsIup01RkIiIRNx29mD2VlTxm39qduDDoSAREYnoX5DJlcf24K+zVvPxpt1hl9NmKEhERGr5xmkDSEuK52dTPwq7lDZDQSIiUkvH9CSuH9+Hfy7exAert4ddTpugIBERqeOacb3plJ7EL17VVklTKEhEROpIT07gayf3ZfqyrcxYviXsclo9BYmISD2+eFxPOmel8ItXPtLUKY1QkIiI1CMlMZ6vn9qf91fv4F8faeqUQ1GQiIg04JKibvTslMYvXvmY6mptlTREQSIi0oDE+Di+cVp/Fm3YxUsLN4RdTqulIBEROYRzhxfSPz+D376+TFslDQg0SMxslZktMLO5ZtbgZQ3NbLSZVZnZxUHWIyJyuOLjjBsm9OOjTbt5fYnGSurTElskE9x9REOXeDSzeOBO4JUWqEVE5LCdc3QXundM5Z5/LdMRXPVoDbu2bgKeBRT1ItIqJcTHMfmkvsxbs4N3l28Nu5xWJ+ggceBVM5tjZpPqrjSzQuAC4L5DvYiZTTKzYjMrLikpCahUEZGGXTSyG/mZyfzuzWVhl9LqBB0k49x9JHAWcIOZja+z/jfAf7l71aFexN3vd/cidy/Ky8sLqlYRkQalJMZz3Yl9mL5sq+bgqiPQIHH39ZGfm4EpwJg6TYqAJ8xsFXAxcK+ZnR9kTSIiR+qKY3uQnZrIvW8uD7uUViWwIDGzdDPLPHAfmAgsrN3G3Xu7ey937wU8A/yHu/89qJpERKKRnpzANeN68dqiTXy0UdcrOSDILZICYJqZzQNmAy+6+1Qzm2xmkwN8XxGRwFx9fC/SkuK5+42lYZfSaiQE9cLuvgIYXs/yegfW3f3qoGoREWkuOWlJfPXEPtz9+lKuGLOFcf1ywy4pdK3h8F8RkTblP07uS89Oadz294WU7T/ksULtgoJEROQwpSTG83/nD2Pllj3c95YG3hUkIiJH4MT+eZw7vCv3/ms5K0pKwy4nVAoSEZEjdNs5g0lOjOO2vy9s11OnKEhERI5QfmYK/3nmIGYs38pzc9eHXU5oFCQiIlG4YkwPhnfP4f9eXMSusv1hlxMKBYmISBTi44z/O28YW/dU8OvXPg67nFAoSEREonRUt2y+MKYHj7z7CUs27gq7nBanIBERaQa3ThxIZkoC33/uw3Y38K4gERFpBh3Sk7j1jIHMXrmN5+e1r4F3BYmISDO5fHQPjirM5o4XF7O7HQ28K0hERJpJfJzxo/OGsnl3Ob99o/1cAEtBIiLSjI7p0YFLi7rx0LSV7WbgXUEiItLMvnPWYDJTErhtykKqq2N/4F1BIiLSzDqmJ/HfnxtM8Sfbeap4TdjlBE5BIiISgEtGdWNMr4785OUlbC0tD7ucQClIREQCYGbcccEw9lZUcsdLi8MuJ1CBBomZrTKzBWY218yK61l/npnNP7DezE4Ish4RkZbUvyCTSeP78Lf31zFj+ZawywlMS2yRTHD3Ee5eVM+614Hh7j4CuBZ4oAXqERFpMTed0l3vz+0AAArbSURBVJ8eHWuuplheGZtXUwx115a7l/pncwmkA7F/eIOItCspifHcfv4wVpTs4e7Xl4ZdTiCCDhIHXjWzOWY2qb4GZnaBmS0BXqRmq6S+NpMiu76KS0pKAixXRKT5nTQgj4tHdeO+t1awYO3OsMtpdkEHyTh3HwmcBdxgZuPrNnD3Ke4+CDgfuL2+F3H3+929yN2L8vLygq1YRCQA3zt7CJ3Sk7j1mXlUVFaHXU6zCjRI3H195OdmYAow5hBt3wb6mllukDWJiIQhOy2ROy44iiUbd3Pvm7E1fUpgQWJm6WaWeeA+MBFYWKdNPzOzyP2RQBKwNaiaRETCdPqQAs4b0ZV73ljG4g2xM31KkFskBcA0M5sHzAZedPepZjbZzCZH2lwELDSzucDvgMu8vU3kLyLtyg8/P5SctMSY2sVlbe3vdlFRkRcXH3RKiohImzF14QYm/+V9zh3eld9cNoK4OAv8Pc1sTgOnYURNZ7aLiLSwM4d14b/OHMTz89bzg+fb/hUVE8IuQESkPfrayX3ZsbeCP7y9gg5piXxr4sCwSzpiChIRkZB856xB7Ni7n7vfWEZ2WhJfOaF32CUdEQWJiEhIDkzsuHPffm7/xyJe/XAjZx/dhTOHdSY/MyXs8ppMg+0iIiErr6ziD2+t4Pl561m2uRQzGN2rI18Y052zj+pKUkL0w9lBDrYrSEREWpGPN+3mxfkbeGHeelZs2UNBVjJfGtuLK4/tQU5a0hG/roKkFgWJiLQH1dXOW0tLeGjaSt5ZuoWUxDhumTiQr57Y54heL8gg0RiJiEgrFBdnTBiYz4SB+SzZuIuHpq2kMCc17LLqpSAREWnlBnXO4mcXDw+7jAbphEQREYmKgkRERKKiIBERkagoSEREJCoKEhERiYqCREREoqIgERGRqChIREQkKm1uihQzKwE+qbM4G9jZyLJDPT5wv/ayXGDLEZZZXz2H0+Zw+9PY/Wj60litjbWJpc+mKX2puyzIz0a/Z4de3lZ/zxpaF+1nk+7ueY1WfiTcvc3fgPsbW3aoxwfu11lW3Jz1HE6bw+1PY/ej6Uu0/Ymlz6YpfWnJz0a/Z7H5e9YaP5vGbrGya+uFJiw71OMXGmjTnPUcTpvD7U9T7kcjmv7E0mfTlL7UXRbkZ6Pfs0Mvb6u/Zw2tC/OzOaQ2t2urpZhZsQc0U2ZLi6W+QGz1R31pvWKpP0H3JVa2SIJwf9gFNKNY6gvEVn/Ul9YrlvoTaF+0RSIiIlHRFomIiERFQSIiIlGJ+SAxs4fMbLOZLTyC544yswVmtszM7jYzq7XuJjP7yMw+NLOfNW/Vh6yp2ftjZj80s3VmNjdy+1zzV15vPYF8NpH1t5iZm1lu81XcaE1BfDa3m9n8yOfyqpl1bf7K660niL783MyWRPozxcxymr/yBmsKoj+XRP7/V5tZ4IPy0fShgdf7spktjdy+XGv5If9v1SvIY4tbww0YD4wEFh7Bc2cDYwEDXgbOiiyfAPwTSI48zm/j/fkhcEssfDaRdd2BV6g5cTW3LfcHyKrV5uvAfW24LxOBhMj9O4E72/hnMxgYCLwJFLXWPkTq61VnWUdgReRnh8j9Dofq76FuMb9F4u5vA9tqLzOzvmY21czmmNk7Zjao7vPMrAs1/4nf9Zp/3UeA8yOrvwb81N3LI++xOdhefCag/oQiwL78GvhPoEWPJAmiP+6+q1bTdFqoTwH15VV3r4w0nQl0C7YXnwmoP4vd/aOWqD/yfkfUhwacAbzm7tvcfTvwGnDmkf6diPkgacD9wE3uPgq4Bbi3njaFwNpaj9dGlgEMAE40s1lm9paZjQ602sZF2x+AGyO7HB4ysw7BldqoqPpiZucC69x9XtCFNlHUn42Z3WFma4Arge8HWGtjmuP37IBrqfm2G6bm7E9YmtKH+hQCa2o9PtCvI+pvQhPfNGaYWQZwPPB0rV1/yfU1rWfZgW+DCdRsDh4HjAaeMrM+kQRvUc3Un98Dt0ce3w78kpr/6C0q2r6YWRrwXWp2oYSumT4b3P27wHfN7L+BG4EfNHOpjWquvkRe67tAJfDX5qzxcDRnf8JyqD6Y2TXAzZFl/YCXzKwCWOnuF9Bwv46ov+0uSKjZCtvh7iNqLzSzeGBO5OHz1Pxxrb3p3Q1YH7m/FvhbJDhmm1k1NZOilQRZeAOi7o+7b6r1vD8C/wiy4EOIti99gd7AvMh/rG7A+2Y2xt03Blx7fZrjd622x4AXCSFIaKa+RAZ1zwFODeOLVy3N/dmEod4+ALj7w8DDAGb2JnC1u6+q1WQtcHKtx92oGUtZy5H0N+gBotZwA3pRa4AKmAFcErlvwPAGnvceNVsdBwadPhdZPhn4UeT+AGo2Ea0N96dLrTbfBJ5oq32p02YVLTjYHtBn079Wm5uAZ9pwX84EFgF5LfmZBP27RgsNth9pH2h4sH0lNXtWOkTud2xKf+utK4wPtIV/eR4HNgD7qUnbr1DzrXUqMC/yi/39Bp5bBCwElgP38NlMAEnAXyLr3gdOaeP9eRRYAMyn5ltYl7balzptVtGyR20F8dk8G1k+n5oJ+ArbcF+WUfOla27k1iJHoAXYnwsir1UObAJeaY19oJ4giSy/NvKZLAOuaay/h7ppihQREYlKez1qS0REmomCREREoqIgERGRqChIREQkKgoSERGJioJEYoKZlbbw+z1gZkOa6bWqrGZ234Vm9kJjs+KaWY6Z/UdzvLdIc9DhvxITzKzU3TOa8fUS/LMJBgNVu3Yz+zPwsbvfcYj2vYB/uPuwlqhPpDHaIpGYZWZ5Zvasmb0XuY2LLB9jZjPM7IPIz4GR5Veb2dNm9gLwqpmdbGZvmtkzVnMdjb8euDZDZHlR5H5pZGLFeWY208wKIsv7Rh6/Z2Y/auJW07t8NgFlhpm9bmbvW831Ic6LtPkp0DeyFfPzSNtbI+8z38z+txn/GUUapSCRWHYX8Gt3Hw1cBDwQWb4EGO/ux1Azm+6Paz1nLPBldz8l8vgY4BvAEKAPMK6e90kHZrr7cOBt4Lpa739X5P0bna8oMs/TqdTMLgBQBlzg7iOpuQbOLyNB9h1gubuPcPdbzWwi0B8YA4wARpnZ+MbeT6S5tMdJG6X9OA0YUmtm1CwzywSygT+bWX9qZjZNrPWc19y99jUfZrv7WgAzm0vNXEfT6rxPBZ9NdDkHOD1yfyyfXcvhMeAXDdSZWuu151BzbQiomevox5FQqKZmS6WgnudPjNw+iDzOoCZY3m7g/USalYJEYlkcMNbd99VeaGa/Bf7l7hdExhverLV6T53XKK91v4r6/8/s988GGxtqcyj73H2EmWVTE0g3AHdTc/2RPGCUu+83s1VASj3PN+An7v6Hw3xfkWahXVsSy16l5vodAJjZgem2s4F1kftXB/j+M6nZpQZweWON3X0nNZfTvcXMEqmpc3MkRCYAPSNNdwOZtZ76CnBt5PoUmFmhmeU3Ux9EGqUgkViRZmZra92+Rc0f5aLIAPQiaqb/B/gZ8BMzmw7EB1jTN4BvmdlsoAuws7EnuPsH1Mzkejk1F34qMrNiarZOlkTabAWmRw4X/rm7v0rNrrN3zWwB8Az/HjQigdLhvyIBiVyxcZ+7u5ldDnzB3c9r7HkibY3GSESCMwq4J3Kk1Q5CuHyxSEvQFomIiERFYyQiIhIVBYmIiERFQSIiIlFRkIiISFQUJCIiEpX/B58+5G9orN77AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model training\n",
    "\n",
    "Time to run:\n",
    "\n",
    "* Full data set took about 13 hours using the Nvidia P1000\n",
    "* Full data set was predicted to take about 25 hours with the T4\n",
    "* 10% data took about 1 hour (1:08) using the Nvidia P1000\n",
    "* 10% data is predicted to take about 2.5 hour (actual 2:42) using the Nvidia GTX 1060\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.628462</td>\n",
       "      <td>2.492367</td>\n",
       "      <td>0.530601</td>\n",
       "      <td>10:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated new learner\n"
     ]
    }
   ],
   "source": [
    "# no idea how long nor how much resources this will take\n",
    "# not sure 1e-2 is the right learning rate; maybe 1e-1 or between 1e-2 and 1e-1\n",
    "# using t4\n",
    "# progress bar says this will take around 24 hours... ran for about 52 minutes\n",
    "# gpustat/nvidia-smi indicates currently only using about 5GB of GPU RAM\n",
    "# using p100\n",
    "# progress bar says this will take around 12 hours; took 13:16\n",
    "# at start GPU using about 5GB RAM\n",
    "# after about 8 hours GPU using about 7.5GB RAM.\n",
    "# looks like I could increase batch size...\n",
    "# with bs=64, still only seems to be using about 7GB GPU RAM after running for 15 minutes. \n",
    "# will check after a bit, but likely can increase batch size further\n",
    "\n",
    "if os.path.isfile(str(init_model_file) + '.pth'):\n",
    "    learn.load(init_model_file)\n",
    "    print('loaded learner')\n",
    "else:\n",
    "    learn.fit_one_cycle(1, 5e-2, moms=(0.8,0.7))\n",
    "    learn.save(init_model_file)\n",
    "    print('generated new learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continue from initial training - reload in case just want to continue processing from here.\n",
    "\n",
    "As an FYI pytorch automatically appends .pth to the filename, you cannot provide it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "#learn.load(init_model_file)\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj resp xxmaj care xxmaj note : \\n \\n  xxmaj pt cont trached on cool mist aerosol as</td>\n",
       "      <td>per xxmaj carevue . xxmaj lung sounds coarse dim @ bases suct xxunk th pale yellow sput . xxmaj pt</td>\n",
       "      <td>well carevue carevue . xxmaj pt sounds are , in bases . sm sm . yellow . . xxmaj pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>: \\n  xxmaj swan - xxmaj ganz catheter with tip at the periphery of the central pulmonary artery .</td>\n",
       "      <td>\\n  xxmaj new right internal jugular venous catheter with the tip in the lower superior \\n  vena cava</td>\n",
       "      <td>\\n  xxmaj xxmaj pt right subclavian jugular line catheter tip tip tip in the right \\n  vena vena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>. \\n  xxup issues : \\n  - xxup tbm , s / p xxunk and posterior tracheal splinting</td>\n",
       "      <td>via r \\n  thoracotomy [ * * 1 - 23 * * ] \\n  - subcutaneous emphysema \\n</td>\n",
       "      <td>\\n  , xxup fem thoracotomy , * * xxmaj - 28 * * ] . xxup xxmaj xxup \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>\\n  30 \\n  31 \\n  xxmaj glucose \\n  156 \\n  94 \\n  75 \\n</td>\n",
       "      <td>110 \\n  85 \\n  xxmaj other labs : xxup pt / xxup ptt / xxup inr:13.6 / 32.1</td>\n",
       "      <td>xxup : xxup pt / xxup ptt / xxup xxunk / 1.2 / 1.2 , xxup ck / xxup ckmb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxmaj midazolam ( xxmaj versed ) - [ * * 2111 - 12 - 7 * * ] 05:30 xxup</td>\n",
       "      <td>am \\n  xxmaj fentanyl - [ * * 2111 - 12 - 7 * * ] 05:30 xxup am</td>\n",
       "      <td>am \\n  xxup ventilator : [ * * xxmaj - 2 - 26 * * ] 10:00 xxup am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has been trained for 4 epochs already\n"
     ]
    }
   ],
   "source": [
    "prev_cycles = 0\n",
    "\n",
    "if os.path.isfile(cycles_file):\n",
    "    with open(cycles_file, 'rb') as f:\n",
    "        prev_cycles = pickle.load(f)\n",
    "print('This model has been trained for', prev_cycles, 'epochs already')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now fine tune language model\n",
    "\n",
    "Performance notes w/P100 GPU:\n",
    "\n",
    "* at batch size of 128 takes about 1:14:00 per epoch; GPU usage is about 14GB; RAM usage is about 10GB\n",
    "* at batch size of 96 takes about 1:17:00 per epoch; GPU usage is about  9GB; RAM usage is about 10GB\n",
    "* at batch size of 48 takes about 1:30:00 per epoch; GPU usage is about  5GB; RAM usage is about 10GB\n",
    "\n",
    "With `learn.fit_one_cycle(8, 5e-3, moms=(0.8,0.7))` (8 cycles)\n",
    "* gets from about 62.7% accuracy to 67.6% accuracy\n",
    "* Total time: 9:54:16\n",
    "\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "    0 \t1.926960 \t1.832659 \t0.627496 \t1:14:14\n",
    "    1 \t1.808083 \t1.755725 \t0.637424 \t1:14:15\n",
    "    2 \t1.747903 \t1.697741 \t0.645431 \t1:14:15\n",
    "    3 \t1.714081 \t1.652703 \t0.652703 \t1:14:19\n",
    "    4 \t1.637801 \t1.602961 \t0.660170 \t1:14:15\n",
    "    5 \t1.596906 \t1.553225 \t0.668557 \t1:14:14\n",
    "    6 \t1.572020 \t1.519172 \t0.674477 \t1:14:26\n",
    "    7 \t1.517364 \t1.510010 \t0.676342 \t1:14:14\n",
    "\n",
    "\n",
    "Output from first 3 runs:\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.828720 \t1.741310 \t0.646276 \t3:03:05\n",
    "\n",
    "     1 addtional run of fit_one_cycle complete\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.736914 \t1.701096 \t0.652299 \t3:03:00\n",
    "\n",
    "     2 addtional run of fit_one_cycle complete\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.699437 \t1.677218 \t0.655742 \t3:03:02\n",
    "\n",
    "     3 addtional run of fit_one_cycle complete\n",
    "    completed 3 new training epochs\n",
    "    completed 3 total training epochs\n",
    "    \n",
    "Output from next 4 runs:\n",
    "\n",
    "    loaded existing learner from /home/seth/mimic/mimic_lm_fine_tuned_3\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.693833 \t1.664847 \t0.658170 \t3:03:05\n",
    "\n",
    "         1 addtional run of fit_one_cycle complete\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.745765 \t1.653829 \t0.659691 \t3:02:57\n",
    "\n",
    "         2 addtional run of fit_one_cycle complete\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.741647 \t1.648660 \t0.660596 \t3:02:53\n",
    "\n",
    "         3 addtional run of fit_one_cycle complete\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.672191 \t1.643600 \t0.661175 \t3:02:40\n",
    "\n",
    "         4 addtional run of fit_one_cycle complete\n",
    "    completed 4 new training epochs\n",
    "    completed 7 total training epochs\n",
    "\n",
    "Output from next 4 runs:\n",
    "\n",
    "    loaded existing learner from /home/seth/mimic/mimic_lm_fine_tuned_7\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.701067 \t1.638409 \t0.661831 \t3:02:46\n",
    "\n",
    "         1 addtional run of fit_one_cycle complete\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.672565 \t1.636598 \t0.662079 \t3:02:55\n",
    "\n",
    "         2 addtional run of fit_one_cycle complete\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.715523 \t1.635751 \t0.662418 \t3:03:00\n",
    "\n",
    "         3 addtional run of fit_one_cycle complete\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "        0 \t1.682663 \t1.632025 \t0.662714 \t3:02:57\n",
    "\n",
    "         4 addtional run of fit_one_cycle complete\n",
    "    completed 4 new training epochs\n",
    "    completed 11 total training epochs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now testing with differnt learning rate 5e-2\n",
      "This model has been trained for 4 epochs already\n",
      "loaded existing learner from /home/seth/mimic/mimic_lm_fine_tuned_4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.997188</td>\n",
       "      <td>1.990023</td>\n",
       "      <td>0.607164</td>\n",
       "      <td>10:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1 addtional run of fit_one_cycle complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.023669</td>\n",
       "      <td>1.993085</td>\n",
       "      <td>0.607259</td>\n",
       "      <td>10:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     2 addtional run of fit_one_cycle complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.949204</td>\n",
       "      <td>1.991918</td>\n",
       "      <td>0.607305</td>\n",
       "      <td>10:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     3 addtional run of fit_one_cycle complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.970876</td>\n",
       "      <td>1.991939</td>\n",
       "      <td>0.606908</td>\n",
       "      <td>10:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     4 addtional run of fit_one_cycle complete\n",
      "completed 4 new training epochs\n",
      "completed 8 total training epochs\n"
     ]
    }
   ],
   "source": [
    "print('now testing with differnt learning rate 5e-2')\n",
    "\n",
    "# if want to continue training existing model, set to True\n",
    "# if want to start fresh from the initialized language model, set to False\n",
    "# also, make sure to remove any previously created saved states before changing\n",
    "# flag back to continue\n",
    "continue_flag = True\n",
    "########################################################\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "\n",
    "if continue_flag:\n",
    "    # mostly a duplicate of the previous cell, but necessary to make sure if just this cell\n",
    "    # is run, everything works correctly in continue mode\n",
    "    if os.path.isfile(cycles_file):\n",
    "        with open(cycles_file, 'rb') as f:\n",
    "            prev_cycles = pickle.load(f)\n",
    "        print('This model has been trained for', prev_cycles, 'epochs already')    \n",
    "    file = lm_base_file + str(prev_cycles)\n",
    "    learner_file = base_path/file\n",
    "    if os.path.isfile(str(learner_file) + '.pth'):\n",
    "        learn.load(learner_file)\n",
    "        print('loaded existing learner from', str(learner_file))\n",
    "    else:\n",
    "        # should not continue as could not find specified file\n",
    "        print('existing learner file (', learner_file, 'not found')\n",
    "        assert(False)\n",
    "else:\n",
    "    prev_cycles = 0\n",
    "\n",
    "########################################################\n",
    "# set this to how many additional cycles you want to run\n",
    "########################################################\n",
    "num_cycles = 4\n",
    "########################################################\n",
    "\n",
    "# learn.fit_one_cycle(4, 5e-2, moms=(0.8,0.7))\n",
    "# print('    ', n + 1, 'addtional run of fit_one_cycle complete')\n",
    "# file = lm_base_file + str(prev_cycles + n + 1)\n",
    "# learner_file = base_path/file\n",
    "# learn.save(learner_file)\n",
    "# with open(cycles_file, 'wb') as f:\n",
    "#     pickle.dump(prev_cycles + n + 1, f)\n",
    "# release_mem()\n",
    "\n",
    "\n",
    "for n in range(num_cycles):\n",
    "    learn.fit_one_cycle(1, 5e-2, moms=(0.8,0.7))\n",
    "    print('    ', n + 1, 'addtional run of fit_one_cycle complete')\n",
    "    file = lm_base_file + str(prev_cycles + n + 1)\n",
    "    learner_file = base_path/file\n",
    "    learn.save(learner_file)\n",
    "    with open(cycles_file, 'wb') as f:\n",
    "        pickle.dump(prev_cycles + n + 1, f)\n",
    "    release_mem()\n",
    "    \n",
    "print('completed', num_cycles, 'new training epochs')\n",
    "print('completed', num_cycles + prev_cycles, 'total training epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cycles_file, 'wb') as f:\n",
    "    pickle.dump(4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 9:54:16 <p><table style='width:375px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>1.926960</th>\n",
       "    <th>1.832659</th>\n",
       "    <th>0.627496</th>\n",
       "    <th>1:14:14</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.808083</th>\n",
       "    <th>1.755725</th>\n",
       "    <th>0.637424</th>\n",
       "    <th>1:14:15</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.747903</th>\n",
       "    <th>1.697741</th>\n",
       "    <th>0.645431</th>\n",
       "    <th>1:14:15</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>1.714081</th>\n",
       "    <th>1.652703</th>\n",
       "    <th>0.652703</th>\n",
       "    <th>1:14:19</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>1.637801</th>\n",
       "    <th>1.602961</th>\n",
       "    <th>0.660170</th>\n",
       "    <th>1:14:15</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>1.596906</th>\n",
       "    <th>1.553225</th>\n",
       "    <th>0.668557</th>\n",
       "    <th>1:14:14</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>1.572020</th>\n",
       "    <th>1.519172</th>\n",
       "    <th>0.674477</th>\n",
       "    <th>1:14:26</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>1.517364</th>\n",
       "    <th>1.510010</th>\n",
       "    <th>0.676342</th>\n",
       "    <th>1:14:14</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jupyter/mimic/mimic_lm_fine_tuned_3.pth']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_pattern = lm_base_file + '*'\n",
    "training_files = glob.glob(str(base_path/fn_pattern))\n",
    "training_files.sort()\n",
    "training_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to load the last file\n",
    "learn.load(training_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism \n",
      "  but showed no PE , but did show some pulmonary edema . She has had \n",
      "  some mild dyspnea on exertion but has improved . She was brought to the \n",
      "  ED for further evaluation\n",
      "For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism or dissection . \n",
      "  She was extubated today and given 1 unit of prbcs for Hct of 24 . She is \n",
      "  afebrile , HR in the 120s , BP stable . She is\n"
     ]
    }
   ],
   "source": [
    "# test the language generation capabilities of this model (not the point, but is interesting)\n",
    "TEXT = \"For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2\n",
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder(enc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the encoder:\n",
    "\n",
    "```python\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "learn.load_encoder(enc_file)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now based on our language model, train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_file = 'mimic_cl.pickle'\n",
    "filename = base_path/class_file\n",
    "\n",
    "if os.path.isfile(filename):\n",
    "    data_cl = load_data(base_path, file, bs=bs)\n",
    "else:\n",
    "    data_cl = (TextList.from_df(df, cols='', vocab=data_lm.vocab)\n",
    "               #grab all the text files in path\n",
    "               .split_by_folder(valid='test')\n",
    "               #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "               .label_from_folder(classes=['neg', 'pos'])\n",
    "               #label them all with their folders\n",
    "               .databunch(bs=bs))\n",
    "\n",
    "data_cl.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c42a15b2c7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cl.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.CATEGORY.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1676"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.DESCRIPTION.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(filename):\n",
    "    data_lm = load_data(base_path, file, bs=bs)\n",
    "else:\n",
    "    data_lm = (TextList.from_df(df, 'texts.csv', cols='TEXT')\n",
    "               #df has several columns; actual text is in column TEXT\n",
    "               .split_by_rand_pct(valid_pct=valid_pct, seed=seed)\n",
    "               #We randomly split and keep 10% for validation\n",
    "               .label_from_df(cols='DESCRIPTION')\n",
    "               #We want to do a language model so we label accordingly\n",
    "               .databunch(bs=bs))\n",
    "    data_lm.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the version from the original example\n",
    "```python\n",
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs))\n",
    "\n",
    "data_clas.save('data_clas.pkl')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(data_cl, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder(enc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change learning rate based on results from the above plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
