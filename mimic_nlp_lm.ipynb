{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using FAST.AI for Medical NLP - Step 1 Build a langauge model\n",
    "\n",
    "Exploring the MIMIC III data set medical notes.\n",
    "\n",
    "Tried working with the full dataset, but almost every training step takes many hours (~13 for initial training), predicted 14+ per epoch for fine tuning, and we need to do many epochs.\n",
    "\n",
    "Instead will try to work with just 10% sample... Not sure that will work though\n",
    "\n",
    "A few notes:\n",
    "* See https://docs.fast.ai/text.transform.html#Tokenizer for details on what various artificial tokens (e.g xxup, xxmaj, etc.) mean\n",
    "* To view nicely formatted documentation on the fastai library, run commands like: ` doc(learn.lr_find)`\n",
    "\n",
    "### To Do:\n",
    "* need to evalate how changing the learning rate would alter training time\n",
    "* need to evalate how changing the learning rate would alter accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import gc\n",
    "from pympler import asizeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to verify that Torch can find and use your GPU, run the following code:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These next cells can be used to get an idea of the speed up provided by a GPU for some operations (from https://course.fast.ai/gpu_tutorial.html)\n",
    "```python\n",
    "import torch\n",
    "t_cpu = torch.rand(500,500,500)\n",
    "%timeit t_cpu @ t_cpu\n",
    "# separate cell \n",
    "t_gpu = torch.rand(500,500,500).cuda()\n",
    "%timeit t_gpu @ t_gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data set too large to work with in reasonable time due to limted GPU resources\n",
    "pct_data_sample = 0.1\n",
    "# how much to hold out for validation\n",
    "valid_pct = 0.1\n",
    "\n",
    "# pandas doesn't understand ~, so provide full path\n",
    "base_path = Path.home() / 'mimic'\n",
    "\n",
    "# files used during processing - all aggregated here\n",
    "notes_file = base_path/'noteevents.pickle'\n",
    "lm_file = 'mimic_lm.pickle' # actual file is at base_path/lm_file but due to fastai function, have to pass file name separately\n",
    "init_model_file = base_path/'mimic_fit_head'\n",
    "cycles_file = base_path/'num_iterations.pickle'\n",
    "lm_base_file = 'mimic_lm_fine_tuned_'\n",
    "enc_file = 'mimic_fine_tuned_enc'\n",
    "class_file = 'mimic_cl.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this doesn't free memory, can restart Python kernel.\n",
    "# if that still doesn't work, try OS items mentioned here: https://docs.fast.ai/dev/gpu.html\n",
    "def release_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to see what has already been imported\n",
    "#whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Random Number seed for repeatability; set Batch Size to control GPU memory\n",
    "\n",
    "See **\"Performance notes\"** section below for how setting batch size impacts GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "# previously used 48; worked fine but never seemed to use even half of GPU memory; 64 still on the small side\n",
    "bs=96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While parsing a CSV and converting to a dataframe is pretty fast, loading a pickle file is much faster.\n",
    "\n",
    "For load time and size comparison:\n",
    "* `NOTEEVENTS.csv` is ~ 3.8GB in size\n",
    "  ```\n",
    "  CPU times: user 51.2 s, sys: 17.6 s, total: 1min 8s\n",
    "  Wall time: 1min 47s\n",
    "  ```\n",
    "* `noteevents.pickle` is ~ 3.7 GB in size\n",
    "  ```\n",
    "  CPU times: user 2.28 s, sys: 3.98 s, total: 6.26 s\n",
    "  Wall time: 6.26 s\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading noteevent pickle file\n",
      "CPU times: user 1.72 s, sys: 2.91 s, total: 4.64 s\n",
      "Wall time: 4.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "orig_df = pd.DataFrame()\n",
    "if os.path.isfile(notes_file):\n",
    "    print('Loading noteevent pickle file')\n",
    "    orig_df = pd.read_pickle(notes_file)\n",
    "else:\n",
    "    print('Could not find noteevent pickle file; creating it')\n",
    "    # run this the first time to covert CSV to Pickle file\n",
    "    orig_df = pd.read_csv(base_path/'NOTEEVENTS.csv', low_memory=False, memory_map=True)\n",
    "    orig_df.to_pickle(notes_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to data set size and performance reasons, working with a 10% sample. Use same random see to get same results from subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orig_df.sample(frac=pct_data_sample, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to free up some memory\n",
    "# orig_df = None\n",
    "# del orig_df\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: 936 MB\n"
     ]
    }
   ],
   "source": [
    "print('df:', int(asizeof.asizeof(df) / 1024 / 1024), 'MB')\n",
    "#print('orig_df:', asizeof.asizeof(orig_df))\n",
    "#print('data_lm:', asizeof.asizeof(data_lm, detail=1))\n",
    "#print asizeof.asized(obj, detail=1).format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>STORETIME</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>CGID</th>\n",
       "      <th>ISERROR</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1292716</th>\n",
       "      <td>1295263</td>\n",
       "      <td>2549</td>\n",
       "      <td>159440.0</td>\n",
       "      <td>2132-04-02</td>\n",
       "      <td>2132-04-02 13:09:00</td>\n",
       "      <td>2132-04-02 13:35:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>18566.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CCU NSG TRANSFER SUMMARY UPDATE: RESP FAILURE\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160271</th>\n",
       "      <td>1175599</td>\n",
       "      <td>29621</td>\n",
       "      <td>190624.0</td>\n",
       "      <td>2149-02-23</td>\n",
       "      <td>2149-02-23 03:27:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radiology</td>\n",
       "      <td>CHEST (PORTABLE AP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[**2149-2-23**] 3:27 AM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1549380</th>\n",
       "      <td>1555118</td>\n",
       "      <td>22384</td>\n",
       "      <td>142591.0</td>\n",
       "      <td>2185-03-26</td>\n",
       "      <td>2185-03-26 17:58:00</td>\n",
       "      <td>2185-03-26 18:01:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>16985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respiratory Care\\nPt remains intubated (#7.5 E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>5743</td>\n",
       "      <td>690</td>\n",
       "      <td>152820.0</td>\n",
       "      <td>2182-09-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>Report</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Admission Date:  [**2182-9-12**]       Dischar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014768</th>\n",
       "      <td>2023163</td>\n",
       "      <td>25560</td>\n",
       "      <td>156143.0</td>\n",
       "      <td>2154-11-18</td>\n",
       "      <td>2154-11-18 10:44:00</td>\n",
       "      <td>2154-11-18 17:08:00</td>\n",
       "      <td>Nursing/other</td>\n",
       "      <td>Report</td>\n",
       "      <td>16888.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neonatology\\nOn exam pink active non-dysmorphi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ROW_ID  SUBJECT_ID   HADM_ID   CHARTDATE            CHARTTIME  \\\n",
       "1292716  1295263        2549  159440.0  2132-04-02  2132-04-02 13:09:00   \n",
       "1160271  1175599       29621  190624.0  2149-02-23  2149-02-23 03:27:00   \n",
       "1549380  1555118       22384  142591.0  2185-03-26  2185-03-26 17:58:00   \n",
       "7474        5743         690  152820.0  2182-09-14                  NaN   \n",
       "2014768  2023163       25560  156143.0  2154-11-18  2154-11-18 10:44:00   \n",
       "\n",
       "                   STORETIME           CATEGORY          DESCRIPTION     CGID  \\\n",
       "1292716  2132-04-02 13:35:00      Nursing/other               Report  18566.0   \n",
       "1160271                  NaN          Radiology  CHEST (PORTABLE AP)      NaN   \n",
       "1549380  2185-03-26 18:01:00      Nursing/other               Report  16985.0   \n",
       "7474                     NaN  Discharge summary               Report      NaN   \n",
       "2014768  2154-11-18 17:08:00      Nursing/other               Report  16888.0   \n",
       "\n",
       "         ISERROR                                               TEXT  \n",
       "1292716      NaN  CCU NSG TRANSFER SUMMARY UPDATE: RESP FAILURE\\...  \n",
       "1160271      NaN  [**2149-2-23**] 3:27 AM\\n CHEST (PORTABLE AP) ...  \n",
       "1549380      NaN  Respiratory Care\\nPt remains intubated (#7.5 E...  \n",
       "7474         NaN  Admission Date:  [**2182-9-12**]       Dischar...  \n",
       "2014768      NaN  Neonatology\\nOn exam pink active non-dysmorphi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ROW_ID           int64\n",
       "SUBJECT_ID       int64\n",
       "HADM_ID        float64\n",
       "CHARTDATE       object\n",
       "CHARTTIME       object\n",
       "STORETIME       object\n",
       "CATEGORY        object\n",
       "DESCRIPTION     object\n",
       "CGID           float64\n",
       "ISERROR        float64\n",
       "TEXT            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208318, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to build initial version of language model; If running with full dataset, requires a **LOT** of RAM; using a **LOT** of CPU helps it to happen quickly as well\n",
    "\n",
    "Questions:\n",
    "\n",
    "* why does this only seem to use CPU? (applies to both both textclasdatabunch and textlist)\n",
    "* for 100% of the mimic noteevents data:\n",
    "  * run out of memory at 32 GB, error at 52 GB, trying 72GB now... got down to only 440MB free; if crash again, increase memory\n",
    "  * now at 20vCPU and 128GB RAM; ok up to 93%; got down to 22GB available\n",
    "  * succeeded with 20CPU and 128GB RAM...\n",
    "* try smaller batch size? will that reduce memory requirements?\n",
    "* with 10% dataset sample, it seems I could get by with perhaps 32GB system RAM\n",
    "\n",
    "For comparison:\n",
    "* 10% language model is ~ 1.2 GB in size\n",
    "  * Time to load existing language model:\n",
    "    ```\n",
    "    CPU times: user 3.29 s, sys: 844 ms, total: 4.14 s\n",
    "    Wall time: 12.6 s\n",
    "    ```\n",
    "  * Time to build language model:\n",
    "    ```\n",
    "    CPU times: user 36.9 s, sys: 8.56 s, total: 45.4 s\n",
    "    Wall time: 3min 27s\n",
    "    ```\n",
    "* 100% language model is...\n",
    "  * Time to load existing language model:\n",
    "  * Time to build language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading existing language model\n",
      "CPU times: user 264 ms, sys: 112 ms, total: 376 ms\n",
      "Wall time: 373 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tmpfile = base_path/lm_file\n",
    "\n",
    "if os.path.isfile(tmpfile):\n",
    "    print('loading existing language model')\n",
    "    data_lm = load_data(base_path, lm_file, bs=bs)\n",
    "else:\n",
    "    print('creating new language model')\n",
    "    data_lm = (TextList.from_df(df, 'texts.csv', cols='TEXT')\n",
    "               #df has several columns; actual text is in column TEXT\n",
    "               .split_by_rand_pct(valid_pct=valid_pct, seed=seed)\n",
    "               #We randomly split and keep 10% for validation\n",
    "               .label_for_lm()\n",
    "               #We want to do a language model so we label accordingly\n",
    "               .databunch(bs=bs))\n",
    "    data_lm.save(tmpfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If need to view more data, run appropriate line to make display wider/show more columns...\n",
    "```python\n",
    "# default 20\n",
    "pd.get_option('display.max_columns')\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_columns', None) # show all\n",
    "# default 50\n",
    "pd.get_option('display.max_colwidth')\n",
    "pd.set_option('display.max_colwidth', -1) # show all\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pacs . xxmaj bp went back to 150 / 80 . xxup hr varies between 80s to low 90s at rest up to 1-teens with activity . xxup bp varies more widely between 1-teens / 70s at rest up to 170 / 90s with activity . xxmaj she continues on dilt 90 mg po qid . xxmaj she was xxup k+ replaced today . \\n  xxup resp : xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>and was beta complete . xxmaj twins born by c / xxup s. xxmaj apgars were 9,9 . xxmaj infant emerged vigorous , and crying , bulb suctioned and given tactile stim , xxmaj no xxup o2 needed . xxmaj infant placed on radiant warmer . xxmaj initial rectal temp 97.3 . xxmaj infant warmed by radiant warmer , with stable temps for remainder of this shift . xxmaj warmer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>inr:17.6 / 35.9 / 1.6 , xxup ck / xxup ckmb / \\n  xxmaj troponin - xxup xxunk / 6 / 0.03 , xxmaj differential - xxmaj neuts:79.9 % , xxmaj lymph:10.8 % , \\n  xxmaj mono:5.8 % , xxmaj eos:3.3 % , xxmaj ca++:8.0 mg / dl , xxmaj mg++:2.0 mg / dl , xxup po4:1.8 mg / dl \\n  xxmaj assessment and xxmaj plan \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>and he no longer feels that he is \\n  working hard to breathe and says that he is very comfortable . \\n  xxmaj the xxmaj cardiology xxmaj team was consulted . xxmaj the patient received \\n  three echocardiograms during hospitalization to date . xxmaj he has \\n  3 + mitral regurgitation associated with his mitral valve \\n  vegetation . xxmaj the patient was started on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[ * * xxmaj last xxmaj name ( namepattern1 ) 1782 * * ] at 11:15 a.m. on [ * * 2181 - 2 - 20 * * ] . \\n \\n  xxbos xxmaj renal failure , acute ( xxmaj acute renal failure , xxup arf ) \\n  xxmaj assessment : \\n  xxmaj pt . anuric s / p nephrectomy . \\n  xxmaj action : \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()\n",
    "# how to look at original version of text\n",
    "#df[df['TEXT'].str.contains('being paralyzed were discussed', case=False)].TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as of June 2019, this automatically loads and initializes the model based on WT103 from\n",
    "# https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz; will auto download if not already on disk\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Learning rate graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial model training\n",
    "\n",
    "Time to run:\n",
    "\n",
    "* Full data set took about 13 hours using the Nvidia P1000\n",
    "* Full data set was predicted to take about 25 hours with the T4\n",
    "* 10% data took about 1 hour (1:08) using the Nvidia P1000\n",
    "* 10% data is predicted to take about 2.5 hour (actual 2:42) using the Nvidia GTX 1060\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded learner\n"
     ]
    }
   ],
   "source": [
    "# no idea how long nor how much resources this will take\n",
    "# not sure 1e-2 is the right learning rate; maybe 1e-1 or between 1e-2 and 1e-1\n",
    "# using t4\n",
    "# progress bar says this will take around 24 hours... ran for about 52 minutes\n",
    "# gpustat/nvidia-smi indicates currently only using about 5GB of GPU RAM\n",
    "# using p100\n",
    "# progress bar says this will take around 12 hours; took 13:16\n",
    "# at start GPU using about 5GB RAM\n",
    "# after about 8 hours GPU using about 7.5GB RAM.\n",
    "# looks like I could increase batch size...\n",
    "# with bs=64, still only seems to be using about 7GB GPU RAM after running for 15 minutes. \n",
    "# will check after a bit, but likely can increase batch size further\n",
    "#\n",
    "# note about number of epochs/cycle length: Using a value of 1 does a rapid increase and\n",
    "# decrease of learning rate and end result gets almost the save result as 2 but in half\n",
    "# the time\n",
    "if os.path.isfile(str(init_model_file) + '.pth'):\n",
    "    learn.load(init_model_file)\n",
    "    print('loaded learner')\n",
    "else:\n",
    "    learn.fit_one_cycle(1, 5e-2, moms=(0.8,0.7))\n",
    "    learn.save(init_model_file)\n",
    "    print('generated new learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continue from initial training - reload in case just want to continue processing from here.\n",
    "\n",
    "As an FYI pytorch automatically appends .pth to the filename, you cannot provide it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "#learn.load(init_model_file)\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj resp xxmaj care xxmaj note : \\n \\n  xxmaj pt cont trached on cool mist aerosol as</td>\n",
       "      <td>per xxmaj carevue . xxmaj lung sounds coarse dim @ bases suct xxunk th pale yellow sput . xxmaj pt</td>\n",
       "      <td>tent tolerated carevue carevue . xxmaj pt sounds are suct at bases . sm thick thick yellow sput . xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5 - 8 * * ] 04:25 xxup am \\n  [ * * 2136 - 5 - 9 *</td>\n",
       "      <td>* ] 04:20 xxup am \\n  [ * * 2136 - 5 - 12 * * ] 03:19 xxup</td>\n",
       "      <td>* ] xxup xxup am \\n  xxup * * 2139 - 11 - 5 * * ] xxup xxup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>: \\n  xxmaj swan - xxmaj ganz catheter with tip at the periphery of the central pulmonary artery .</td>\n",
       "      <td>\\n  xxmaj new right internal jugular venous catheter with the tip in the lower superior \\n  vena cava</td>\n",
       "      <td>venous . xxmaj xxmaj the xxup - jugular line catheter in tip tip in the mid \\n  vena vena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1 xxup dose xxup of xxup iv xxup lopressor . xxup standing xxup lopressor xxup dose xxup increased . \\n</td>\n",
       "      <td>xxup pt xxup alert xxup and xxup follows xxup commands xxup but xxup does xxup not xxup always xxup</td>\n",
       "      <td>xxmaj xxunk xxup has xxup and xxup oriented xxup commands . and xxup not xxup not xxup want xxup to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>. \\n  xxup issues : \\n  - xxup tbm , s / p xxunk and posterior tracheal splinting</td>\n",
       "      <td>via r \\n  thoracotomy [ * * 1 - 23 * * ] \\n  - subcutaneous emphysema \\n</td>\n",
       "      <td>, xxup \\n  side . * * xxmaj - 2 * * ] . xxmaj xxmaj \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cycles_file, 'wb') as f:\n",
    "    pickle.dump(8, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has been trained for 8 epochs already\n"
     ]
    }
   ],
   "source": [
    "prev_cycles = 0\n",
    "\n",
    "if os.path.isfile(cycles_file):\n",
    "    with open(cycles_file, 'rb') as f:\n",
    "        prev_cycles = pickle.load(f)\n",
    "print('This model has been trained for', prev_cycles, 'epochs already')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are pre-existing automatic save states. Remove these files if no longer needed.\n",
      "/home/jupyter/mimic/mimic_lm_fine_tuned_0_auto_0.pth\n",
      "/home/jupyter/mimic/mimic_lm_fine_tuned_0_auto_1.pth\n",
      "/home/jupyter/mimic/mimic_lm_fine_tuned_2_auto_0.pth\n",
      "/home/jupyter/mimic/mimic_lm_fine_tuned_2_auto_1.pth\n",
      "/home/jupyter/mimic/mimic_lm_fine_tuned_4_auto_0.pth\n",
      "/home/jupyter/mimic/mimic_lm_fine_tuned_4_auto_1.pth\n",
      "/home/jupyter/mimic/mimic_lm_fine_tuned__auto_0.pth\n",
      "/home/jupyter/mimic/mimic_lm_fine_tuned__auto_1.pth\n"
     ]
    }
   ],
   "source": [
    "#temp_files = glob.glob(str(base_path/'*_auto_*'))\n",
    "#if len(training_files) > 0:\n",
    "rfiles = glob.glob(str(base_path/'*_auto_*'))\n",
    "rfiles.sort()\n",
    "if (len(rfiles) > 0):\n",
    "    print('There are pre-existing automatic save states. Remove these files if no longer needed.')\n",
    "for f in rfiles:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Now fine tune language model\n",
    "\n",
    "Performance notes w/P100 GPU:\n",
    "\n",
    "* at batch size of 128 takes about 1:14:00 per epoch; GPU usage is about 14GB; RAM usage is about 10GB\n",
    "* at batch size of 96 takes about 1:17:00 per epoch; GPU usage is about  9GB; RAM usage is about 10GB\n",
    "* at batch size of 48 takes about 1:30:00 per epoch; GPU usage is about  5GB; RAM usage is about 10GB\n",
    "\n",
    "With `learn.fit_one_cycle(8, 5e-3, moms=(0.8,0.7))` (8 cycles)\n",
    "* gets from about 62.7% accuracy to 67.6% accuracy\n",
    "* Total time: 9:54:16\n",
    "\n",
    "\n",
    "    epoch \ttrain_loss \tvalid_loss \taccuracy \ttime\n",
    "    0 \t1.926960 \t1.832659 \t0.627496 \t1:14:14\n",
    "    1 \t1.808083 \t1.755725 \t0.637424 \t1:14:15\n",
    "    2 \t1.747903 \t1.697741 \t0.645431 \t1:14:15\n",
    "    3 \t1.714081 \t1.652703 \t0.652703 \t1:14:19\n",
    "    4 \t1.637801 \t1.602961 \t0.660170 \t1:14:15\n",
    "    5 \t1.596906 \t1.553225 \t0.668557 \t1:14:14\n",
    "    6 \t1.572020 \t1.519172 \t0.674477 \t1:14:26\n",
    "    7 \t1.517364 \t1.510010 \t0.676342 \t1:14:14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_learner_load(lf):\n",
    "    if os.path.isfile(str(lf) + '.pth'):\n",
    "        learn.load(lf)\n",
    "        print('loaded existing learner from', str(lf))\n",
    "    else:\n",
    "        # should not continue as could not find specified file\n",
    "        print('existing learner file (', lf, ') not found, cannot continue')\n",
    "        print('previous epoch may have only partially completed')\n",
    "        print(' --- try updating prev_cycles to match or copy file to correct name.')\n",
    "        assert(False)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has been trained for 2 epochs already\n",
      "No auto save files exist from interupted training.\n",
      "loaded existing learner from /home/jupyter/mimic/mimic_lm_fine_tuned_2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Total time: 10:39 <p><table style='width:375px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>1.869730</th>\n",
       "    <th>1.929068</th>\n",
       "    <th>0.607264</th>\n",
       "    <th>05:19</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.705812</th>\n",
       "    <th>1.792771</th>\n",
       "    <th>0.630864</th>\n",
       "    <th>05:19</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed 2 new training epochs\n",
      "completed 4 total training epochs\n"
     ]
    }
   ],
   "source": [
    "# if want to continue training existing model, set to True\n",
    "# if want to start fresh from the initialized language model, set to False\n",
    "# also, make sure to remove any previously created saved states before changing\n",
    "# flag back to continue\n",
    "continue_flag = False\n",
    "# Resume interrupted training\n",
    "resume_flag = True\n",
    "########################################################\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "\n",
    "########################################################\n",
    "# set this to how many cycles you want to run\n",
    "num_cycles = 15\n",
    "########################################################\n",
    "lm_base_file = 'mimic_lm_fine_tuned_'\n",
    "if continue_flag:\n",
    "    if os.path.isfile(cycles_file):\n",
    "        with open(cycles_file, 'rb') as f:\n",
    "            prev_cycles = pickle.load(f)\n",
    "        print('This model has been trained for', prev_cycles, 'epochs already')  \n",
    "else:\n",
    "    prev_cycles = 0\n",
    "\n",
    "file = lm_base_file + str(prev_cycles)\n",
    "learner_file = base_path/file\n",
    "callback_save_file = str(learner_file) + '_auto'\n",
    "fn_pattern = callback_save_file + '*'\n",
    "\n",
    "\n",
    "# for one cycle learning with learning rate annealing - where to resume from\n",
    "start_epoch = 0\n",
    "\n",
    "if resume_flag:\n",
    "    training_files = glob.glob(str(base_path/fn_pattern))\n",
    "    if len(training_files) > 0:\n",
    "        training_files.sort()\n",
    "        completed_cycles = int(re.split('_|\\.', training_files[-1])[-2])\n",
    "        if completed_cycles < (num_cycles - 1):\n",
    "            # need to load the last file\n",
    "            print('Previous training cycle of', num_cycles, 'did not complete; finished',\n",
    "                  completed_cycles + 1, 'cycles. Loading last save...')\n",
    "            # load just filename, drop extension of .pth as that is automatically appended inside load function\n",
    "            learn.load(os.path.splitext(training_files[-1])[0])\n",
    "            start_epoch = completed_cycles + 1\n",
    "        else:\n",
    "            print('Previous training cycle of', num_cycles, 'completed fully.')\n",
    "            learn = custom_learner_load(learner_file)\n",
    "    else:\n",
    "        print('No auto save files exist from interupted training.')\n",
    "        if continue_flag:\n",
    "            learn = custom_learner_load(learner_file)\n",
    "        else:\n",
    "            print('Starting training with base language model')\n",
    "else:\n",
    "    if continue_flag:\n",
    "        learn = custom_learner_load(learner_file)\n",
    "    else:\n",
    "        print('Starting training with base language model')\n",
    "    # remove any auto saves\n",
    "    training_files = glob.glob(str(base_path/fn_pattern))\n",
    "    if len(training_files) > 0:\n",
    "        for f in training_files:\n",
    "            print('Deleting', f)\n",
    "            os.remove(f)\n",
    "\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(num_cycles, 5e-3, moms=(0.8,0.7),\n",
    "                    callbacks=[\n",
    "                        callbacks.SaveModelCallback(learn, every='epoch', monitor='accuracy', name=callback_save_file),\n",
    "                        # CSVLogger only logs when num_cycles are complete\n",
    "                        callbacks.CSVLogger(learn, filename='mimic_lm_fine_tune_history', append=True),\n",
    "                        callbacks.EarlyStoppingCallback(learn, monitor='accuracy', min_delta=0.005, patience=5)\n",
    "                    ],\n",
    "                    start_epoch=start_epoch)\n",
    "file = lm_base_file + str(prev_cycles + num_cycles)\n",
    "learner_file = base_path/file\n",
    "learn.save(learner_file)\n",
    "\n",
    "with open(cycles_file, 'wb') as f:\n",
    "    pickle.dump(num_cycles + prev_cycles, f)\n",
    "release_mem()\n",
    "    \n",
    "print('completed', num_cycles, 'new training epochs')\n",
    "print('completed', num_cycles + prev_cycles, 'total training epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate different learning rates.\n",
    "\n",
    "Use this block of code to compare how well a few different learning rates work\n",
    "\n",
    "Found that `5e-3` works best with `learn.unfreeze()`\n",
    "\n",
    "```python\n",
    "num_cycles = 4\n",
    "prev_cycles = 4\n",
    "\n",
    "for lr in [1e-3, 5e-3, 1e-2, 5e-2, 1e-1]:\n",
    "    print('now testing with multiple epochs and learning rate of', lr)\n",
    "    print('This model has been trained for', prev_cycles, 'epochs already')    \n",
    "    file = lm_base_file + str(prev_cycles)\n",
    "    learner_file = base_path/file\n",
    "    learn.load(learner_file)\n",
    "    learn.unfreeze()\n",
    "    print('loaded existing learner from', str(learner_file))\n",
    "\n",
    "\n",
    "    learn.fit_one_cycle(num_cycles, lr, moms=(0.8,0.7))\n",
    "    file = lm_base_file + str(prev_cycles + num_cycles + 1)\n",
    "    learner_file = base_path/file\n",
    "    learn.save(learner_file)\n",
    "    release_mem()\n",
    "\n",
    "    print('completed', num_cycles, 'new training epochs')\n",
    "    print('completed', num_cycles + prev_cycles, 'total training epochs')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism \n",
      "  but showed no PE , but did show some pulmonary edema . She has had \n",
      "  some mild dyspnea on exertion but has improved . She was brought to the \n",
      "  ED for further evaluation\n",
      "For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism or dissection . \n",
      "  She was extubated today and given 1 unit of prbcs for Hct of 24 . She is \n",
      "  afebrile , HR in the 120s , BP stable . She is\n"
     ]
    }
   ],
   "source": [
    "# test the language generation capabilities of this model (not the point, but is interesting)\n",
    "TEXT = \"For confirmation, she underwent CTA of the lung which was negative for pulmonary embolism\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2\n",
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder(enc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the encoder:\n",
    "\n",
    "```python\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "learn.load_encoder(enc_file)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
