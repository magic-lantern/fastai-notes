{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Creating your own dataset from Google Images\n",
    "\n",
    "*by: Francisco Ingham and Jeremy Howard. Inspired by [Adrian Rosebrock](https://www.pyimagesearch.com/2017/12/04/how-to-create-a-deep-learning-dataset-using-google-images/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "In this tutorial we will see how to easily create an image dataset through Google Images. **Note**: You will have to repeat these steps for any new category you want to Google (e.g once for dogs and once for cats)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search and scroll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [Google Images](http://images.google.com) and search for the images you are interested in. The more specific you are in your Google Search, the better the results and the less manual pruning you will have to do.\n",
    "\n",
    "Scroll down until you've seen all the images you want to download, or until you see a button that says 'Show more results'. All the images you scrolled past are now available to download. To get more, click on the button, and continue scrolling. The maximum number of images Google Images shows is 700.\n",
    "\n",
    "It is a good idea to put things you want to exclude into the search query, for instance if you are searching for the Eurasian wolf, \"canis lupus lupus\", it might be a good idea to exclude other variants:\n",
    "\n",
    "    \"canis lupus lupus\" -dog -arctos -familiaris -baileyi -occidentalis\n",
    "\n",
    "You can also limit your results to show only photos by clicking on Tools and selecting Photos from the Type dropdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download into file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you must run some Javascript code in your browser which will save the URLs of all the images you want for you dataset.\n",
    "\n",
    "Press <kbd>Ctrl</kbd><kbd>Shift</kbd><kbd>J</kbd> in Windows/Linux and <kbd>Cmd</kbd><kbd>Opt</kbd><kbd>J</kbd> in Mac, and a small window the javascript 'Console' will appear. That is where you will paste the JavaScript commands.\n",
    "\n",
    "You will need to get the urls of each of the images. You can do this by running the following commands:\n",
    "\n",
    "```javascript\n",
    "urls = Array.from(document.querySelectorAll('.rg_di .rg_meta')).map(el=>JSON.parse(el.textContent).ou);\n",
    "window.open('data:text/csv;charset=utf-8,' + escape(urls.join('\\n')));\n",
    "```\n",
    "\n",
    "### Query Parameters for images.google.com\n",
    "\n",
    "* Grizzly Bear: \"grizzly bear\" -statue -bengal\n",
    "* Black Bear: \"black bear\" -asiatic -cartoon -grizzly -toy\n",
    "* Teddy Bear: \"teddy bear\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create directory and upload urls file into your server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an appropriate name for your labeled images. You can run these steps multiple times to grab different labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'black'\n",
    "file = 'black_bear_urls.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'teddys'\n",
    "file = 'teddy_bear_urls.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'grizzly'\n",
    "file = 'grizzly_bear_urls.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to run this line once per each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/bears')\n",
    "dest = path/folder\n",
    "dest.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, upload your urls file. You just need to press 'Upload' in your working directory and select your file, then click 'Upload' for each of the displayed files.\n",
    "\n",
    "![uploaded file](images/download_images/upload.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will need to download you images from their respective urls.\n",
    "\n",
    "fast.ai has a function that allows you to do just that. You just have to specify the urls filename and the destination folder and this function will download and save all images that can be opened. If they have some problem in being opened, they will not be saved.\n",
    "\n",
    "Let's download our images! Notice you can choose a maximum number of images to be downloaded. In this case we will not download all the urls.\n",
    "\n",
    "You will need to run this line once for every category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "        \t/* Turns off some styling */\n",
       "        \tprogress {\n",
       "\n",
       "            \t/* gets rid of default border in Firefox and Opera. */\n",
       "            \tborder: none;\n",
       "\n",
       "            \t/* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "            \tbackground-size: auto;\n",
       "            }\n",
       "\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='197' class='' max='200', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      98.50% [197/200 00:11<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error https://lookaside.fbsbx.com/lookaside/crawler/media/?media_id=734881709882503 'content-length'\n",
      "Error https://pixl.varagesale.com/http://s3.amazonaws.com/hopshop-image-store-production/134633702/83e6c7a4acdd16016a928716210d9ae1.jpg?_ver=large_uploader_thumbnail&w=640&h=640&fit=crop&s=586e111d09a647ce1956e750f7660b9f 'content-length'\n",
      "Error http://legitgifts.com/wp-content/uploads/2017/10/LED-Teddy-1.jpg 'content-length'\n",
      "Error https://www.buytshirtsonline.co.uk/images/mumbles-classic-jointed-teddy-bear-p2964-133408_image.jpg 'content-length'\n",
      "Error https://eternityledglow.com/wp-content/uploads/2014/10/glow-teddy-bear.jpg HTTPSConnectionPool(host='eternityledglow.com', port=443): Max retries exceeded with url: /wp-content/uploads/2014/10/glow-teddy-bear.jpg (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f0e789171d0>: Failed to establish a new connection: [Errno 110] Connection timed out',))\n"
     ]
    }
   ],
   "source": [
    "download_images(path/file, dest, max_pics=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have problems download, try with `max_workers=0` to see exceptions:\n",
    "# download_images(path/file, dest, max_pics=20, max_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Here up must be repeated multiple times - once per class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can remove any images that can't be opened:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['teddys','grizzly','black']\n",
    "for c in classes:\n",
    "    print(c)\n",
    "    verify_images(path/c, delete=True, max_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.2,\n",
    "        ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Let's take a look at some of our pictures then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(7,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes, data.c, len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet34, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "learn = create_cnn(data, models.resnet34, metrics=error_rate\n",
    "learn.fit_one_cycle(4)\n",
    "```\n",
    "\n",
    "```\n",
    "Total time: 00:59\n",
    "epoch  train_loss  valid_loss  error_rate\n",
    "1      0.736959    0.124658    0.000000    (00:15)\n",
    "2      0.392833    0.030153    0.008696    (00:14)\n",
    "3      0.254588    0.032688    0.017391    (00:14)\n",
    "4      0.186582    0.036088    0.017391    (00:14)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.save('bears-stage-1')\n",
    "learn.load('bears-stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc(learn.lr_find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.fit_one_cycle(2, max_lr=slice(3e-5,3e-4))\n",
    "# interesting that this has vastly improved training loss, but slightly higher error_rate overall\n",
    "learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('bears-stage-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up\n",
    "\n",
    "Some of our top losses aren't due to bad performance by our model. There are images in our data set that shouldn't be.\n",
    "\n",
    "Using the `FileDeleter` widget from `fastai.widgets` we can prune our top losses, removing photos that don't belong.\n",
    "\n",
    "First we need to get the file paths from our top_losses. Here's a handy function that pulls out all our top_losses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.widgets import *\n",
    "\n",
    "losses,idxs = interp.top_losses()\n",
    "top_loss_paths = data.valid_ds.x[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass in these paths to our widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FileDeleter(file_paths=top_loss_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flag photos for deletion by clicking 'Delete'. Then click 'Confirm' to delete flagged photos and keep the rest in that row. The `File_Deleter` will show you a new row of images until there are no more to show. In this case, the widget will show you images until there are none left from `top_losses`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting your model in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably want to use CPU for inference, except at massive scale (and you almost certainly don't need to train in real-time). If you don't have a GPU that happens automatically. You can test your model on CPU like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastai.defaults.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(path/'black'/'00000021.jpg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['black', 'grizzly', 'teddys']\n",
    "data2 = ImageDataBunch.single_from_classes(path, classes, tfms=get_transforms(), size=224).normalize(imagenet_stats)\n",
    "learn = create_cnn(data2, models.resnet34)\n",
    "learn.load('stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class,pred_idx,outputs = learn.predict(img)\n",
    "pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you might create a route something like this ([thanks](https://github.com/simonw/cougar-or-not) to Simon Willison for the structure of this code):\n",
    "\n",
    "```python\n",
    "@app.route(\"/classify-url\", methods=[\"GET\"])\n",
    "async def classify_url(request):\n",
    "    bytes = await get_bytes(request.query_params[\"url\"])\n",
    "    img = open_image(BytesIO(bytes))\n",
    "    _,_,losses = learner.predict(img)\n",
    "    return JSONResponse({\n",
    "        \"predictions\": sorted(\n",
    "            zip(cat_learner.data.classes, map(float, losses)),\n",
    "            key=lambda p: p[1],\n",
    "            reverse=True\n",
    "        )\n",
    "    })\n",
    "```\n",
    "\n",
    "(This example is for the [Starlette](https://www.starlette.io/) web app toolkit.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Things that can go wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most of the time things will train fine with the defaults\n",
    "- There's not much you really need to tune (despite what you've heard!)\n",
    "- Most likely are\n",
    "  - Learning rate\n",
    "  - Number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate (LR) too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet34, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1, max_lr=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate (LR) too low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet34, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we had this result:\n",
    "\n",
    "```\n",
    "Total time: 00:57\n",
    "epoch  train_loss  valid_loss  error_rate\n",
    "1      1.030236    0.179226    0.028369    (00:14)\n",
    "2      0.561508    0.055464    0.014184    (00:13)\n",
    "3      0.396103    0.053801    0.014184    (00:13)\n",
    "4      0.316883    0.050197    0.021277    (00:15)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, max_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as taking a really long time, it's getting too many looks at each image, so may overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet34, metrics=error_rate, pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Too many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = ImageDataBunch.from_folder(path, train=\".\", valid_pct=0.9, bs=32, \n",
    "        ds_tfms=get_transforms(do_flip=False, max_rotate=0, max_zoom=1, max_lighting=0, max_warp=0\n",
    "                              ),size=224, num_workers=4).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet50, metrics=error_rate, ps=0, wd=0)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(40, slice(1e-6,1e-4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
